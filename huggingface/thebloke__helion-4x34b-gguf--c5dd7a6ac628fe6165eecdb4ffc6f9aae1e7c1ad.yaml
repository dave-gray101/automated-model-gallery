- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: helion-4x34b.Q2_K.gguf
    template:
      chat: chatml
      completion: chatml
  description: TheBloke/Helion-4x34B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: chatml.tmpl
    sha256: 96edc939f785d5cf5b35abb7289f60e0ad92b3f6fbd75f4f95647f559af5fa2e
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/chatml.tmpl
  - filename: helion-4x34b.Q2_K.gguf
    sha256: d95582712a11ba40d3a09705449e2a13887b38d90efd6b0ad8088928cc871a01
    uri: 
      https://huggingface.co/TheBloke/Helion-4x34B-GGUF/resolve/main/helion-4x34b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__helion-4x34b-gguf__helion-4x34b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - yi
  - moe
  - base_model:Weyaxi/Helion-4x34B
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Helion-4x34B-GGUF
