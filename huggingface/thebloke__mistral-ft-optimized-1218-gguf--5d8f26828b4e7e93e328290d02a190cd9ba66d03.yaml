- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q2_K.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q2_K.gguf
    sha256: bfd471552be4f5e7294ca0062a0066543a669bf08ff5b689b3644898ab4c86fc
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q3_K_L.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q3_K_L.gguf
    sha256: c7331851a52d4f80c03a5a676a56b8e838bfa31fb9e1c694a1a083f764b74c1c
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q3_K_M.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q3_K_M.gguf
    sha256: 2bd26cc955f1f7de1d27bce86ac583b0f8cf6e387375fe216687cdf3eda6c8d6
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q3_K_S.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q3_K_S.gguf
    sha256: b374aaf4b88cae1b08e576458ffb3d4d1460579cbc5645a24a97e84b648be696
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q4_0.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q4_0.gguf
    sha256: 9319a85bdfbcb7889d030f0a18a5f901555f2742a253bdbd596f2ea74f89d6a1
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q4_K_M.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q4_K_M.gguf
    sha256: 9166c07c85830cb8054c0ba1181932d9d2c87b4a80dc0cbea16e91d6882b83e2
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q4_K_S.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q4_K_S.gguf
    sha256: b56ad05d3fc2b1ee69b8e4c111bea58ebb8bc72ef574a01cea2b53105872f23e
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q5_0.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q5_0.gguf
    sha256: bad9d8a68cc2a431eb2f7d591ecb6ebc8988a891cd5dca689866d60713002cb7
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q5_K_M.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q5_K_M.gguf
    sha256: 6b8968e5d19edeed7762d5cc640fb1d275c1dee52f0e8beae9f56567ba159150
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q5_K_S.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q5_K_S.gguf
    sha256: f734946f234aa479fe50c1c63455ec73f686aa301c632917f62ee121b1d5a1b0
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q6_K.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q6_K.gguf
    sha256: 5fa978a5ee61570ee91dacd216715db76708dbb32b3f94e8ee1230e9cbdbf7eb
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: mistral-ft-optimized-1218.Q8_0.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - mistral configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q8_0.gguf
    sha256: 0336cfa0a16c5266d79d82284126b7204afde92bf5f43b7aae59b22807b41e3c
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q2_K.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q2_K.gguf
    sha256: bfd471552be4f5e7294ca0062a0066543a669bf08ff5b689b3644898ab4c86fc
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q3_K_L.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q3_K_L.gguf
    sha256: c7331851a52d4f80c03a5a676a56b8e838bfa31fb9e1c694a1a083f764b74c1c
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q3_K_M.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q3_K_M.gguf
    sha256: 2bd26cc955f1f7de1d27bce86ac583b0f8cf6e387375fe216687cdf3eda6c8d6
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q3_K_S.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q3_K_S.gguf
    sha256: b374aaf4b88cae1b08e576458ffb3d4d1460579cbc5645a24a97e84b648be696
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q4_0.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q4_0.gguf
    sha256: 9319a85bdfbcb7889d030f0a18a5f901555f2742a253bdbd596f2ea74f89d6a1
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q4_K_M.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q4_K_M.gguf
    sha256: 9166c07c85830cb8054c0ba1181932d9d2c87b4a80dc0cbea16e91d6882b83e2
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q4_K_S.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q4_K_S.gguf
    sha256: b56ad05d3fc2b1ee69b8e4c111bea58ebb8bc72ef574a01cea2b53105872f23e
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q5_0.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q5_0.gguf
    sha256: bad9d8a68cc2a431eb2f7d591ecb6ebc8988a891cd5dca689866d60713002cb7
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q5_K_M.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q5_K_M.gguf
    sha256: 6b8968e5d19edeed7762d5cc640fb1d275c1dee52f0e8beae9f56567ba159150
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q5_K_S.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q5_K_S.gguf
    sha256: f734946f234aa479fe50c1c63455ec73f686aa301c632917f62ee121b1d5a1b0
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q6_K.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q6_K.gguf
    sha256: 5fa978a5ee61570ee91dacd216715db76708dbb32b3f94e8ee1230e9cbdbf7eb
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mistral-ft-optimized-1218.Q8_0.gguf
    template:
      chat: thebloke__mistral-ft-optimized-1218-gguf
      completion: thebloke__mistral-ft-optimized-1218-gguf
  description: TheBloke/mistral-ft-optimized-1218-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mistral-ft-optimized-1218-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mistral-ft-optimized-1218-gguf.tmpl
  - filename: mistral-ft-optimized-1218.Q8_0.gguf
    sha256: 0336cfa0a16c5266d79d82284126b7204afde92bf5f43b7aae59b22807b41e3c
    uri: 
      https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF/resolve/main/mistral-ft-optimized-1218.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__mistral-ft-optimized-1218-gguf__mistral-ft-optimized-1218.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - en
  - base_model:OpenPipe/mistral-ft-optimized-1218
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/mistral-ft-optimized-1218-GGUF
