- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q2_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q2_K.gguf
    sha256: b3120838051a061b6d35890ae1a47662be1eb6061eccf5ee5b1852c17a1b197a
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_L.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_L.gguf
    sha256: 53b6523dfa9f332934b295a15e98bcef8d5b2cdc7cb6d84b5a24f9ab364c3635
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_M.gguf
    sha256: 350dfb31b9b7f622c1831dcbde8b637f6b99baec1d1a1ddb54bf522b5f956512
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_S.gguf
    sha256: ce5962b056fe170da98c4add330efe9d4fcd408c2169b1898d53c542ae9227d5
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_0.gguf
    sha256: 4534ceaaacaefb471544b86211f5157e3849f80ee1c130860806869553fd298f
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_K_M.gguf
    sha256: 61c4f66e878329cd1a9b5f58949d76e276c976bfeee16b40aef9889a2c8bb319
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_K_S.gguf
    sha256: 14b109896cdb0064b278f3d98f386eef1ac54aca76703ef2f5ecc85adb0ff2ee
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_0.gguf
    sha256: af060af9882fa53d8c882eee45229ce5809c1acecba3d02f9477d9bb973eab9d
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_K_M.gguf
    sha256: b77895f6b14927232dea135d8443d002983a9ce917c9d97cab45d75e3502b522
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_K_S.gguf
    sha256: 11961a90f4bf37566e11d6bca917731988d4fb29cbfb090d1ca0f510fbcd16bc
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q6_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q6_K.gguf
    sha256: d4faf135734470fe196b41fc9a271509295530bc0437caf2888ff127712874df
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q8_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q8_0.gguf
    sha256: 85e78953f7415bcd2eca148354d2b96d0fbfd978c8e6c93002e826c2b47854c9
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q2_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q2_K.gguf
    sha256: b3120838051a061b6d35890ae1a47662be1eb6061eccf5ee5b1852c17a1b197a
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_L.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_L.gguf
    sha256: 53b6523dfa9f332934b295a15e98bcef8d5b2cdc7cb6d84b5a24f9ab364c3635
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_M.gguf
    sha256: 350dfb31b9b7f622c1831dcbde8b637f6b99baec1d1a1ddb54bf522b5f956512
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_S.gguf
    sha256: ce5962b056fe170da98c4add330efe9d4fcd408c2169b1898d53c542ae9227d5
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_0.gguf
    sha256: 4534ceaaacaefb471544b86211f5157e3849f80ee1c130860806869553fd298f
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_K_M.gguf
    sha256: 61c4f66e878329cd1a9b5f58949d76e276c976bfeee16b40aef9889a2c8bb319
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_K_S.gguf
    sha256: 14b109896cdb0064b278f3d98f386eef1ac54aca76703ef2f5ecc85adb0ff2ee
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_0.gguf
    sha256: af060af9882fa53d8c882eee45229ce5809c1acecba3d02f9477d9bb973eab9d
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_K_M.gguf
    sha256: b77895f6b14927232dea135d8443d002983a9ce917c9d97cab45d75e3502b522
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_K_S.gguf
    sha256: 11961a90f4bf37566e11d6bca917731988d4fb29cbfb090d1ca0f510fbcd16bc
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q6_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q6_K.gguf
    sha256: d4faf135734470fe196b41fc9a271509295530bc0437caf2888ff127712874df
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q8_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q8_0.gguf
    sha256: 85e78953f7415bcd2eca148354d2b96d0fbfd978c8e6c93002e826c2b47854c9
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q2_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q2_K.gguf
    sha256: b3120838051a061b6d35890ae1a47662be1eb6061eccf5ee5b1852c17a1b197a
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_L.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_L.gguf
    sha256: 53b6523dfa9f332934b295a15e98bcef8d5b2cdc7cb6d84b5a24f9ab364c3635
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_M.gguf
    sha256: 350dfb31b9b7f622c1831dcbde8b637f6b99baec1d1a1ddb54bf522b5f956512
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q3_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q3_K_S.gguf
    sha256: ce5962b056fe170da98c4add330efe9d4fcd408c2169b1898d53c542ae9227d5
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_0.gguf
    sha256: 4534ceaaacaefb471544b86211f5157e3849f80ee1c130860806869553fd298f
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_K_M.gguf
    sha256: 61c4f66e878329cd1a9b5f58949d76e276c976bfeee16b40aef9889a2c8bb319
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q4_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q4_K_S.gguf
    sha256: 14b109896cdb0064b278f3d98f386eef1ac54aca76703ef2f5ecc85adb0ff2ee
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_0.gguf
    sha256: af060af9882fa53d8c882eee45229ce5809c1acecba3d02f9477d9bb973eab9d
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_K_M.gguf
    sha256: b77895f6b14927232dea135d8443d002983a9ce917c9d97cab45d75e3502b522
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q5_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q5_K_S.gguf
    sha256: 11961a90f4bf37566e11d6bca917731988d4fb29cbfb090d1ca0f510fbcd16bc
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q6_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q6_K.gguf
    sha256: d4faf135734470fe196b41fc9a271509295530bc0437caf2888ff127712874df
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: Manticore-13B.Q8_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Manticore-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: Manticore-13B.Q8_0.gguf
    sha256: 85e78953f7415bcd2eca148354d2b96d0fbfd978c8e6c93002e826c2b47854c9
    uri: 
      https://huggingface.co/TheBloke/Manticore-13B-GGUF/resolve/main/Manticore-13B.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: thebloke__manticore-13b-gguf__Manticore-13B.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
  - dataset:ehartford/wizard_vicuna_70k_unfiltered
  - dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
  - dataset:QingyiSi/Alpaca-CoT
  - dataset:teknium/GPT4-LLM-Cleaned
  - dataset:teknium/GPTeacher-General-Instruct
  - dataset:metaeval/ScienceQA_text_only
  - dataset:hellaswag
  - dataset:tasksource/mmlu
  - dataset:openai/summarize_from_feedback
  - base_model:openaccess-ai-collective/manticore-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Manticore-13B-GGUF
