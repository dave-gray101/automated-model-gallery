- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q2_K.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q2_K.gguf
    sha256: 164442870ad8affc5ca15b7d5e3bfff0e3dfcf5477346552a16ccfe0dbe8bd44
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q3_K_L.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q3_K_L.gguf
    sha256: ae0cf63adef92a8b5ca66b0aad63edcb61f8e1d37a18ee5a0a9630d25c4bf335
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q3_K_M.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q3_K_M.gguf
    sha256: 040d0d9e9d67c4ce962bbbd3471fff3ea42ef6ff50fe3da0a36e147e06e5f065
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q3_K_S.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q3_K_S.gguf
    sha256: 5b31bc4322b0c75918d63df157bd1e42182a1b6b9d744aafc8d6523e41849410
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q4_0.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q4_0.gguf
    sha256: 937956cbbf8e1bd0a2777321354b4d9175ea5589683f7e880cb93ebfc4136f23
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q4_K_M.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q4_K_M.gguf
    sha256: bdc7a49010c29ae9ea89b1950d9c532d8cafda9b8f6b67cbe282bafd230ae18a
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q4_K_S.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q4_K_S.gguf
    sha256: fdd1d51dbc0108ecec3b314ecf7070e64d28d8eae73ecd839136eeb7ef8a5f48
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q5_0.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q5_0.gguf
    sha256: cf4c38738e581a78a180a3ed63f2ee004ea5267bc507d33818e6ee3613548d31
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q5_K_M.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q5_K_M.gguf
    sha256: ef1f7798e73c20a41e3cc4b9ca4a6677d244bd29238ed9d5d1415dafe77cf1c3
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q5_K_S.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q5_K_S.gguf
    sha256: e9947dc53b429976808e92307dab95e7a68b617a7accd02ae927099c866661d7
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q6_K.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q6_K.gguf
    sha256: d91439047c2625c6a503762d2fa54f2b1196dbe4f2902fccf07c9188d923ed7f
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral_11bx2_moe_19b.Q8_0.gguf
    template:
      chat: thebloke__mixtral_11bx2_moe_19b-gguf
      completion: thebloke__mixtral_11bx2_moe_19b-gguf
  description: TheBloke/Mixtral_11Bx2_MoE_19B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral_11bx2_moe_19b-gguf.tmpl
  - filename: mixtral_11bx2_moe_19b.Q8_0.gguf
    sha256: 1cc64c02171f6369bbae85eea0ce519882f5493a62b469d3c2317367aa45a03f
    uri: 
      https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF/resolve/main/mixtral_11bx2_moe_19b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral_11bx2_moe_19b-gguf__mixtral_11bx2_moe_19b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - base_model:cloudyu/Mixtral_11Bx2_MoE_19B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral_11Bx2_MoE_19B-GGUF
