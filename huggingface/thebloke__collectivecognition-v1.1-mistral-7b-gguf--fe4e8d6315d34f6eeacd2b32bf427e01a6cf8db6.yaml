- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q2_K.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q2_K.gguf
    sha256: d802425342b26f40b994c4d9865a87736b24a53bb43b5f01287e74915fa911e2
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf
    sha256: 63772e8bd49caa022d217d3c9b76e86eecb098a2908112b058360e5399f02ebd
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf
    sha256: 1d15a7235dc8dc62c9575c378502e9263c82022fbcb444c8a81a0a0932fea821
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf
    sha256: e2656f892d715cdecbcf87ce3ae121a66600ea8920ce8c43e9202a524772b94d
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q4_0.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q4_0.gguf
    sha256: 175cae478f6cbfdcd3d180fe1d81b3fdf6bf11f8f9b771be035f3b7424d09335
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf
    sha256: c22703d328b58a5392f00d5156382ec9f17bc84793b2df16da4848cbb725da52
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf
    sha256: fac86f08f646bdb424ed3f7f0b1dd0b383a513fc4af3d8b292d715e3c6d0ecfa
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q5_0.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q5_0.gguf
    sha256: d22c035e5841375001cf8af6d2e369c53e84c885c801f01ea24a7eab89da3473
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf
    sha256: c1148239a1aa353da3405f04cb1260d3704fa46a41815c2f6908d782d0a91341
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf
    sha256: 1b7c0c0cef9b239bdf37554b1dd2253637f3eab43013de9dec8db166609caded
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q6_K.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q6_K.gguf
    sha256: 3ec15a4ae82c10b0f71f0fde1cc3140fc00f9e8abfcc76b294b43be5ecd3a952
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 4096
    f16: true
    mmap: true
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q8_0.gguf
    stopwords:
    - <|im_end|>
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - mistral configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q8_0.gguf
    sha256: 5674961fcca4ddeb1d10a9aaf4371da7ca7f4f5e340dbdf97ed7da2a45e13b8b
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q2_K.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q2_K.gguf
    sha256: d802425342b26f40b994c4d9865a87736b24a53bb43b5f01287e74915fa911e2
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf
    sha256: 63772e8bd49caa022d217d3c9b76e86eecb098a2908112b058360e5399f02ebd
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf
    sha256: 1d15a7235dc8dc62c9575c378502e9263c82022fbcb444c8a81a0a0932fea821
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf
    sha256: e2656f892d715cdecbcf87ce3ae121a66600ea8920ce8c43e9202a524772b94d
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q4_0.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q4_0.gguf
    sha256: 175cae478f6cbfdcd3d180fe1d81b3fdf6bf11f8f9b771be035f3b7424d09335
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf
    sha256: c22703d328b58a5392f00d5156382ec9f17bc84793b2df16da4848cbb725da52
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf
    sha256: fac86f08f646bdb424ed3f7f0b1dd0b383a513fc4af3d8b292d715e3c6d0ecfa
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q5_0.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q5_0.gguf
    sha256: d22c035e5841375001cf8af6d2e369c53e84c885c801f01ea24a7eab89da3473
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf
    sha256: c1148239a1aa353da3405f04cb1260d3704fa46a41815c2f6908d782d0a91341
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf
    sha256: 1b7c0c0cef9b239bdf37554b1dd2253637f3eab43013de9dec8db166609caded
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q6_K.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q6_K.gguf
    sha256: 3ec15a4ae82c10b0f71f0fde1cc3140fc00f9e8abfcc76b294b43be5ecd3a952
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: collectivecognition-v1.1-mistral-7b.Q8_0.gguf
    template:
      chat: user-assistant
      completion: user-assistant
  description: TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: user-assistant.tmpl
    sha256: ce3c1ccd2a4526ea15f96564b3ebed50bc921d27bfba5cdf72106a4121b89d58
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/user-assistant.tmpl
  - filename: collectivecognition-v1.1-mistral-7b.Q8_0.gguf
    sha256: 5674961fcca4ddeb1d10a9aaf4371da7ca7f4f5e340dbdf97ed7da2a45e13b8b
    uri: 
      https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1.1-mistral-7b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: 
    thebloke__collectivecognition-v1.1-mistral-7b-gguf__collectivecognition-v1.1-mistral-7b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - mistral
  - mistral-7b
  - instruct
  - finetune
  - gpt4
  - synthetic data
  - distillation
  - sharegpt
  - en
  - dataset:CollectiveCognition/chats-data-2023-09-27
  - base_model:teknium/CollectiveCognition-v1.1-Mistral-7B
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF
