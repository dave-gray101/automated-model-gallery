- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q2_K.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q2_K.gguf
    sha256: f03fde324c1396e604666158cec099f4cb3db9cebd0674021b568fd3c21c0d56
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q3_K_L.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q3_K_L.gguf
    sha256: 06d2ffe75d0391742b4fa8081f0172528f7683a81409194ef878d1424dcb4794
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q3_K_M.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q3_K_M.gguf
    sha256: 435a46c02d50e14ba7e881f68e5a293cfe2575b435c801bac5d34cc132866642
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q3_K_S.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q3_K_S.gguf
    sha256: 60e48b97ac42a06625948570aa94f81fe390246c8feb400e1aef22a124f71008
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q4_0.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q4_0.gguf
    sha256: 502a822294966f5811aa4cfbf9f9f0dbb3167ad63b1ded6d27b8b6df748448b6
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q4_K_M.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q4_K_M.gguf
    sha256: 96511f7498e8059048ab0856316eca7e2b241260c39ed9cec4c428ab9a70cb03
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q4_K_S.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q4_K_S.gguf
    sha256: 4db5a504eeeba518554c9f3e7741cbde22c5ac35d8822e784c19380cd13387e4
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q5_0.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q5_0.gguf
    sha256: 3418bdcb60b7beaf3af4c17b89c4ae7cc6571ed79a16cc7142d3612d4200e825
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q5_K_M.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q5_K_M.gguf
    sha256: 5d20ace3e5fe700632e472b2e08dec12743c9b6c5d7ec0629fb2af6a107c18c6
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q5_K_S.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q5_K_S.gguf
    sha256: 6efc2034a014e71d9c98d17f8604816e82963c242abadf41b490275fd97685dc
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q6_K.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q6_K.gguf
    sha256: a77ecbb872f878a45d2a7c41a86130a75dc9285e0a0302c705c1fdb53b83aea3
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q8_0.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llama configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q8_0.gguf
    sha256: 459458032e87ee7617655b15c255ebc3076aa56a3347fddd576be77ce3ba333c
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q2_K.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q2_K.gguf
    sha256: f03fde324c1396e604666158cec099f4cb3db9cebd0674021b568fd3c21c0d56
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q3_K_L.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q3_K_L.gguf
    sha256: 06d2ffe75d0391742b4fa8081f0172528f7683a81409194ef878d1424dcb4794
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q3_K_M.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q3_K_M.gguf
    sha256: 435a46c02d50e14ba7e881f68e5a293cfe2575b435c801bac5d34cc132866642
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q3_K_S.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q3_K_S.gguf
    sha256: 60e48b97ac42a06625948570aa94f81fe390246c8feb400e1aef22a124f71008
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q4_0.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q4_0.gguf
    sha256: 502a822294966f5811aa4cfbf9f9f0dbb3167ad63b1ded6d27b8b6df748448b6
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q4_K_M.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q4_K_M.gguf
    sha256: 96511f7498e8059048ab0856316eca7e2b241260c39ed9cec4c428ab9a70cb03
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q4_K_S.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q4_K_S.gguf
    sha256: 4db5a504eeeba518554c9f3e7741cbde22c5ac35d8822e784c19380cd13387e4
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q5_0.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q5_0.gguf
    sha256: 3418bdcb60b7beaf3af4c17b89c4ae7cc6571ed79a16cc7142d3612d4200e825
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q5_K_M.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q5_K_M.gguf
    sha256: 5d20ace3e5fe700632e472b2e08dec12743c9b6c5d7ec0629fb2af6a107c18c6
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q5_K_S.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q5_K_S.gguf
    sha256: 6efc2034a014e71d9c98d17f8604816e82963c242abadf41b490275fd97685dc
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q6_K.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q6_K.gguf
    sha256: a77ecbb872f878a45d2a7c41a86130a75dc9285e0a0302c705c1fdb53b83aea3
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-13b-uncensored.Q8_0.gguf
    template:
      chat: guanaco
      completion: guanaco
  description: TheBloke/Guanaco-13B-Uncensored-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: guanaco.tmpl
    sha256: e4256f19ddba1aed444e8b18f2e452c6430029c6248c3ce3e48cc9f319d93bf4
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/guanaco.tmpl
  - filename: guanaco-13b-uncensored.Q8_0.gguf
    sha256: 459458032e87ee7617655b15c255ebc3076aa56a3347fddd576be77ce3ba333c
    uri: 
      https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF/resolve/main/guanaco-13b-uncensored.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__guanaco-13b-uncensored-gguf__guanaco-13b-uncensored.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-13B-Uncensored
  - license:apache-2.0
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GGUF
