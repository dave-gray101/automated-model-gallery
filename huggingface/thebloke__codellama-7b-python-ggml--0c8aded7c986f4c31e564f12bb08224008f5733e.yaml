- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q2_K.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q2_K.bin
    sha256: daad8f9276b661a6b3312d1d4311dced4faeb94f73a5b1dec8c4c2d317560909
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q2_K.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_L.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_L.bin
    sha256: ee7ba37d13a85c7245296d7d86f1e46749e42504ab62936956b2a8066e8036bc
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_L.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_M.bin
    sha256: c325496821fc3db4e53c4f120200a6867ac8b75699c442f0fbe8536b4727706f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_S.bin
    sha256: 917468304e463d7f927c23e0e916fda38f346d6767943abf56fc7f2c50bee4d7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_0.bin
    sha256: bfdd72cd58f887363dd30427d62b0d7467e01f43c175d8d3243dad1930722f3e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_1.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_1.bin
    sha256: 797d7e8a41faa775df7c2c57baa876d1071c176117e2ba0e66a969a810457530
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_1.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_K_M.bin
    sha256: cc2fba82f99e049ea041c74bab0c6056ac685ecd6bb714b132ad2c07392f3cb0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_K_S.bin
    sha256: 99684f331c7e7016b9418f38aa81d806bd1da68ea9ab26f1d5d29766940b8fc4
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_0.bin
    sha256: 1fc82d08dfc1f3112f0656082fe0998c7f26379c2080f069a6955cb110702299
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_1.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_1.bin
    sha256: 66f6fc6bbd3a5e58678398af77f35921442c48a324cb2a46904da6e26c74b66c
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_1.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_K_M.bin
    sha256: 50d5b2199dfa1f5dc073890e2e42ed388a97d3bbe4e08068f8f9155a4672c674
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_K_S.bin
    sha256: 5ef79e1f6fbdc46aa9b557ff6d4e8ade86812f3a5cf67d3c5422ca692a0ccd87
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q6_K.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q6_K.bin
    sha256: ab7c52508a638fa3af290dde0963125e9de48384ada9c2f74decbbfdbb9491eb
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q6_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q6_K.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q8_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q8_0.bin
    sha256: 34367e8f9660aadaf16c211ff30e24737fa0737a4348d12d67062992d9f2857d
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q8_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q8_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q2_K.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q2_K.bin
    sha256: daad8f9276b661a6b3312d1d4311dced4faeb94f73a5b1dec8c4c2d317560909
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q2_K.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_L.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_L.bin
    sha256: ee7ba37d13a85c7245296d7d86f1e46749e42504ab62936956b2a8066e8036bc
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_L.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_M.bin
    sha256: c325496821fc3db4e53c4f120200a6867ac8b75699c442f0fbe8536b4727706f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_S.bin
    sha256: 917468304e463d7f927c23e0e916fda38f346d6767943abf56fc7f2c50bee4d7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_0.bin
    sha256: bfdd72cd58f887363dd30427d62b0d7467e01f43c175d8d3243dad1930722f3e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_1.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_1.bin
    sha256: 797d7e8a41faa775df7c2c57baa876d1071c176117e2ba0e66a969a810457530
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_1.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_K_M.bin
    sha256: cc2fba82f99e049ea041c74bab0c6056ac685ecd6bb714b132ad2c07392f3cb0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_K_S.bin
    sha256: 99684f331c7e7016b9418f38aa81d806bd1da68ea9ab26f1d5d29766940b8fc4
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_0.bin
    sha256: 1fc82d08dfc1f3112f0656082fe0998c7f26379c2080f069a6955cb110702299
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_1.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_1.bin
    sha256: 66f6fc6bbd3a5e58678398af77f35921442c48a324cb2a46904da6e26c74b66c
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_1.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_K_M.bin
    sha256: 50d5b2199dfa1f5dc073890e2e42ed388a97d3bbe4e08068f8f9155a4672c674
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_K_S.bin
    sha256: 5ef79e1f6fbdc46aa9b557ff6d4e8ade86812f3a5cf67d3c5422ca692a0ccd87
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q6_K.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q6_K.bin
    sha256: ab7c52508a638fa3af290dde0963125e9de48384ada9c2f74decbbfdbb9491eb
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q6_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q6_K.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q8_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q8_0.bin
    sha256: 34367e8f9660aadaf16c211ff30e24737fa0737a4348d12d67062992d9f2857d
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q8_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q8_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q2_K.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q2_K.bin
    sha256: daad8f9276b661a6b3312d1d4311dced4faeb94f73a5b1dec8c4c2d317560909
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q2_K.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_L.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_L.bin
    sha256: ee7ba37d13a85c7245296d7d86f1e46749e42504ab62936956b2a8066e8036bc
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_L.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_M.bin
    sha256: c325496821fc3db4e53c4f120200a6867ac8b75699c442f0fbe8536b4727706f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q3_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q3_K_S.bin
    sha256: 917468304e463d7f927c23e0e916fda38f346d6767943abf56fc7f2c50bee4d7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q3_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_0.bin
    sha256: bfdd72cd58f887363dd30427d62b0d7467e01f43c175d8d3243dad1930722f3e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_1.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_1.bin
    sha256: 797d7e8a41faa775df7c2c57baa876d1071c176117e2ba0e66a969a810457530
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_1.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_K_M.bin
    sha256: cc2fba82f99e049ea041c74bab0c6056ac685ecd6bb714b132ad2c07392f3cb0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q4_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q4_K_S.bin
    sha256: 99684f331c7e7016b9418f38aa81d806bd1da68ea9ab26f1d5d29766940b8fc4
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q4_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_0.bin
    sha256: 1fc82d08dfc1f3112f0656082fe0998c7f26379c2080f069a6955cb110702299
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_1.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_1.bin
    sha256: 66f6fc6bbd3a5e58678398af77f35921442c48a324cb2a46904da6e26c74b66c
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_1.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_K_M.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_K_M.bin
    sha256: 50d5b2199dfa1f5dc073890e2e42ed388a97d3bbe4e08068f8f9155a4672c674
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q5_K_S.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q5_K_S.bin
    sha256: 5ef79e1f6fbdc46aa9b557ff6d4e8ade86812f3a5cf67d3c5422ca692a0ccd87
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q5_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q6_K.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q6_K.bin
    sha256: ab7c52508a638fa3af290dde0963125e9de48384ada9c2f74decbbfdbb9491eb
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q6_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q6_K.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: codellama-7b-python.ggmlv3.Q8_0.bin
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGML - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.ggmlv3.Q8_0.bin
    sha256: 34367e8f9660aadaf16c211ff30e24737fa0737a4348d12d67062992d9f2857d
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML/resolve/main/codellama-7b-python.ggmlv3.Q8_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-ggml__codellama-7b-python.ggmlv3.Q8_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGML
