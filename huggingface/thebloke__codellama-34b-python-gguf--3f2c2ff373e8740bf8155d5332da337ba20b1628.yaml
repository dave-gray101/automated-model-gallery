- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q2_K.gguf
    sha256: 9ab4b5ea3b1ba6fa265645ebcd2cd189073600103bcd141d2c8cae0c8fd0540a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_L.gguf
    sha256: e1905903a3c05746a6fb8522455e4077d4d2f9af873a8c53cc7a7351ebc1cb1d
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_M.gguf
    sha256: 390f68798fe0cbc5ef6cecbe0232460f3b5b4b9d67f740589a88785384e17b38
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_S.gguf
    sha256: 87b5b5e8414dcdd601c4f89902b84b769a149cf359d62c2b3a7b24d1caaa70ce
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_0.gguf
    sha256: a67244d8f818570a61380b0b580b20070b6d9bba894a0eecbb1e8bbe763a8487
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_K_M.gguf
    sha256: 4b0973794389e473eee27328c5b70e568b07aed32ee05e7c775b9dc40a6f969f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_K_S.gguf
    sha256: 899fdc98181d6af35c6455f69174bbfbe4a36651073a23f8224ea74a75575d22
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_0.gguf
    sha256: 1aeb27e477716ac56af7548968e411e221db2ed8d78d712b8a5a41c504ea65e0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_K_M.gguf
    sha256: 45c7ff5681f11fdb6abceb5a94602935db955ac43129ce94f6486304025730d2
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_K_S.gguf
    sha256: bb70f23e0e29668ea6bf1fcb434b6afacc0a53f99c42d94c8dc2e1b58d142775
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q6_K.gguf
    sha256: 4f0cb76b62e23297944f61c2b829728291c5146f62a2659c87faee7c2e44115e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q8_0.gguf
    sha256: 853878963ea0827272f4d7502b3a9d4e9f75e192e684197705bc2795af119b3c
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q2_K.gguf
    sha256: 9ab4b5ea3b1ba6fa265645ebcd2cd189073600103bcd141d2c8cae0c8fd0540a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_L.gguf
    sha256: e1905903a3c05746a6fb8522455e4077d4d2f9af873a8c53cc7a7351ebc1cb1d
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_M.gguf
    sha256: 390f68798fe0cbc5ef6cecbe0232460f3b5b4b9d67f740589a88785384e17b38
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_S.gguf
    sha256: 87b5b5e8414dcdd601c4f89902b84b769a149cf359d62c2b3a7b24d1caaa70ce
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_0.gguf
    sha256: a67244d8f818570a61380b0b580b20070b6d9bba894a0eecbb1e8bbe763a8487
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_K_M.gguf
    sha256: 4b0973794389e473eee27328c5b70e568b07aed32ee05e7c775b9dc40a6f969f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_K_S.gguf
    sha256: 899fdc98181d6af35c6455f69174bbfbe4a36651073a23f8224ea74a75575d22
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_0.gguf
    sha256: 1aeb27e477716ac56af7548968e411e221db2ed8d78d712b8a5a41c504ea65e0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_K_M.gguf
    sha256: 45c7ff5681f11fdb6abceb5a94602935db955ac43129ce94f6486304025730d2
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_K_S.gguf
    sha256: bb70f23e0e29668ea6bf1fcb434b6afacc0a53f99c42d94c8dc2e1b58d142775
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q6_K.gguf
    sha256: 4f0cb76b62e23297944f61c2b829728291c5146f62a2659c87faee7c2e44115e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q8_0.gguf
    sha256: 853878963ea0827272f4d7502b3a9d4e9f75e192e684197705bc2795af119b3c
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q2_K.gguf
    sha256: 9ab4b5ea3b1ba6fa265645ebcd2cd189073600103bcd141d2c8cae0c8fd0540a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_L.gguf
    sha256: e1905903a3c05746a6fb8522455e4077d4d2f9af873a8c53cc7a7351ebc1cb1d
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_M.gguf
    sha256: 390f68798fe0cbc5ef6cecbe0232460f3b5b4b9d67f740589a88785384e17b38
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q3_K_S.gguf
    sha256: 87b5b5e8414dcdd601c4f89902b84b769a149cf359d62c2b3a7b24d1caaa70ce
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_0.gguf
    sha256: a67244d8f818570a61380b0b580b20070b6d9bba894a0eecbb1e8bbe763a8487
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_K_M.gguf
    sha256: 4b0973794389e473eee27328c5b70e568b07aed32ee05e7c775b9dc40a6f969f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q4_K_S.gguf
    sha256: 899fdc98181d6af35c6455f69174bbfbe4a36651073a23f8224ea74a75575d22
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_0.gguf
    sha256: 1aeb27e477716ac56af7548968e411e221db2ed8d78d712b8a5a41c504ea65e0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_K_M.gguf
    sha256: 45c7ff5681f11fdb6abceb5a94602935db955ac43129ce94f6486304025730d2
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q5_K_S.gguf
    sha256: bb70f23e0e29668ea6bf1fcb434b6afacc0a53f99c42d94c8dc2e1b58d142775
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q6_K.gguf
    sha256: 4f0cb76b62e23297944f61c2b829728291c5146f62a2659c87faee7c2e44115e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-34b-python.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-34B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-34b-python.Q8_0.gguf
    sha256: 853878963ea0827272f4d7502b3a9d4e9f75e192e684197705bc2795af119b3c
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF/resolve/main/codellama-34b-python.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-34b-python-gguf__codellama-34b-python.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-34b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-34B-Python-GGUF
