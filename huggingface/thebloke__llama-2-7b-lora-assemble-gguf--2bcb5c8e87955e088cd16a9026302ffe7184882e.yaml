- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q2_K.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q2_K.gguf
    sha256: 3f1de24bcfac0d48a9e733fa4acc06fbe90ab081cfea54d9cfc82e3574e2ff9e
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q3_K_L.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q3_K_L.gguf
    sha256: 36a598087b4dc13b31bca21a3a5531e69224698c68f53081f15e158cbb5d4be4
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q3_K_M.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q3_K_M.gguf
    sha256: b4ce1c3ada114e4432b33ca0e3a718cc5f9db54247944d60aa01e47007c25995
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q3_K_S.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q3_K_S.gguf
    sha256: 79f120c3eca8c5c017b0abf43c08582eb79a516b73bcb402160931bba4141319
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q4_0.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q4_0.gguf
    sha256: 99f54516cd73b3604bb58a04a827beeac6f5821bfe3a8754a0b2f9b8d8cd4743
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q4_K_M.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q4_K_M.gguf
    sha256: 09da91a7ad1d8410c00ac40ece6e1af49668f5808871a5c2202d83cfc7aaed48
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q4_K_S.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q4_K_S.gguf
    sha256: e6c637d56af0dc83807e907638e6cacf289c2a398888dae40abd2ce3ce6fbecf
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q5_0.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q5_0.gguf
    sha256: 5f198c264dd26df9f0d4be8300a1366a282df073b75e27028449a74d1e965c1e
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q5_K_M.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q5_K_M.gguf
    sha256: b1418297983a8be37e5951f0ac9f15b90720576b18d54d9718359bc580d8ecf0
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q5_K_S.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q5_K_S.gguf
    sha256: b4c7b8439aa498daaa18c1e2307b26466cd775c86cb6ec578b33ea20aec1b600
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q6_K.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q6_K.gguf
    sha256: 3ecee84a6356d700608be2ecdb864d785b7b5c22e29fd7a9d799c8c22122cfc4
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q8_0.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llama configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q8_0.gguf
    sha256: c8fef35fc43055aa69508a0022c4f68056f9fcb62527d23c7152bc5d9f2610ce
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q2_K.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q2_K.gguf
    sha256: 3f1de24bcfac0d48a9e733fa4acc06fbe90ab081cfea54d9cfc82e3574e2ff9e
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q3_K_L.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q3_K_L.gguf
    sha256: 36a598087b4dc13b31bca21a3a5531e69224698c68f53081f15e158cbb5d4be4
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q3_K_M.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q3_K_M.gguf
    sha256: b4ce1c3ada114e4432b33ca0e3a718cc5f9db54247944d60aa01e47007c25995
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q3_K_S.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q3_K_S.gguf
    sha256: 79f120c3eca8c5c017b0abf43c08582eb79a516b73bcb402160931bba4141319
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q4_0.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q4_0.gguf
    sha256: 99f54516cd73b3604bb58a04a827beeac6f5821bfe3a8754a0b2f9b8d8cd4743
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q4_K_M.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q4_K_M.gguf
    sha256: 09da91a7ad1d8410c00ac40ece6e1af49668f5808871a5c2202d83cfc7aaed48
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q4_K_S.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q4_K_S.gguf
    sha256: e6c637d56af0dc83807e907638e6cacf289c2a398888dae40abd2ce3ce6fbecf
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q5_0.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q5_0.gguf
    sha256: 5f198c264dd26df9f0d4be8300a1366a282df073b75e27028449a74d1e965c1e
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q5_K_M.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q5_K_M.gguf
    sha256: b1418297983a8be37e5951f0ac9f15b90720576b18d54d9718359bc580d8ecf0
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q5_K_S.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q5_K_S.gguf
    sha256: b4c7b8439aa498daaa18c1e2307b26466cd775c86cb6ec578b33ea20aec1b600
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q6_K.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q6_K.gguf
    sha256: 3ecee84a6356d700608be2ecdb864d785b7b5c22e29fd7a9d799c8c22122cfc4
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-7b-lora-assemble.Q8_0.gguf
    template:
      chat: thebloke__llama-2-7b-lora-assemble-gguf
      completion: thebloke__llama-2-7b-lora-assemble-gguf
  description: TheBloke/Llama-2-7B-LoRA-Assemble-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__llama-2-7b-lora-assemble-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__llama-2-7b-lora-assemble-gguf.tmpl
  - filename: llama-2-7b-lora-assemble.Q8_0.gguf
    sha256: c8fef35fc43055aa69508a0022c4f68056f9fcb62527d23c7152bc5d9f2610ce
    uri: 
      https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF/resolve/main/llama-2-7b-lora-assemble.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__llama-2-7b-lora-assemble-gguf__llama-2-7b-lora-assemble.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - base_model:oh-yeontaek/llama-2-7B-LoRA-assemble
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-7B-LoRA-Assemble-GGUF
