- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral-8x7b-moe-rp-story.Q2_K.gguf
    template:
      chat: thebloke__mixtral-8x7b-moe-rp-story-gguf
      completion: thebloke__mixtral-8x7b-moe-rp-story-gguf
  description: TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
  - filename: mixtral-8x7b-moe-rp-story.Q2_K.gguf
    sha256: c5304a07f6c1922444a28f4dd32976cf62ac99a81d91914d06e2a2cf6882c2d2
    uri: 
      https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF/resolve/main/mixtral-8x7b-moe-rp-story.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral-8x7b-moe-rp-story-gguf__mixtral-8x7b-moe-rp-story.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - not-for-all-audiences
  - nsfw
  - base_model:Undi95/Mixtral-8x7B-MoE-RP-Story
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral-8x7b-moe-rp-story.Q3_K_M.gguf
    template:
      chat: thebloke__mixtral-8x7b-moe-rp-story-gguf
      completion: thebloke__mixtral-8x7b-moe-rp-story-gguf
  description: TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
  - filename: mixtral-8x7b-moe-rp-story.Q3_K_M.gguf
    sha256: 5ccf45e0f117959e46c3acb41f7c3079473687abd90e8da0892b1e62e2f33c7a
    uri: 
      https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF/resolve/main/mixtral-8x7b-moe-rp-story.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral-8x7b-moe-rp-story-gguf__mixtral-8x7b-moe-rp-story.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - not-for-all-audiences
  - nsfw
  - base_model:Undi95/Mixtral-8x7B-MoE-RP-Story
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral-8x7b-moe-rp-story.Q4_0.gguf
    template:
      chat: thebloke__mixtral-8x7b-moe-rp-story-gguf
      completion: thebloke__mixtral-8x7b-moe-rp-story-gguf
  description: TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
  - filename: mixtral-8x7b-moe-rp-story.Q4_0.gguf
    sha256: d84aecc0f1d3ff2bafe98e1dbc1e847137400838bc55471ac4708ffb8e845719
    uri: 
      https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF/resolve/main/mixtral-8x7b-moe-rp-story.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral-8x7b-moe-rp-story-gguf__mixtral-8x7b-moe-rp-story.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - not-for-all-audiences
  - nsfw
  - base_model:Undi95/Mixtral-8x7B-MoE-RP-Story
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral-8x7b-moe-rp-story.Q4_K_M.gguf
    template:
      chat: thebloke__mixtral-8x7b-moe-rp-story-gguf
      completion: thebloke__mixtral-8x7b-moe-rp-story-gguf
  description: TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
  - filename: mixtral-8x7b-moe-rp-story.Q4_K_M.gguf
    sha256: 1886c12d3d2010e20cd7a37d1ed9556a35bae2b4018d9fc5a0d247d4ecb1144b
    uri: 
      https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF/resolve/main/mixtral-8x7b-moe-rp-story.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral-8x7b-moe-rp-story-gguf__mixtral-8x7b-moe-rp-story.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - not-for-all-audiences
  - nsfw
  - base_model:Undi95/Mixtral-8x7B-MoE-RP-Story
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral-8x7b-moe-rp-story.Q5_0.gguf
    template:
      chat: thebloke__mixtral-8x7b-moe-rp-story-gguf
      completion: thebloke__mixtral-8x7b-moe-rp-story-gguf
  description: TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
  - filename: mixtral-8x7b-moe-rp-story.Q5_0.gguf
    sha256: f9516d1ed3d39506e81b209f9e593dc15058bb0dd3648c8a5b15366f4fd554c8
    uri: 
      https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF/resolve/main/mixtral-8x7b-moe-rp-story.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral-8x7b-moe-rp-story-gguf__mixtral-8x7b-moe-rp-story.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - not-for-all-audiences
  - nsfw
  - base_model:Undi95/Mixtral-8x7B-MoE-RP-Story
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral-8x7b-moe-rp-story.Q5_K_M.gguf
    template:
      chat: thebloke__mixtral-8x7b-moe-rp-story-gguf
      completion: thebloke__mixtral-8x7b-moe-rp-story-gguf
  description: TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
  - filename: mixtral-8x7b-moe-rp-story.Q5_K_M.gguf
    sha256: 63745ee73c455ba6dbedf85385d40efc91881259f7f11bf95dd12629e9268322
    uri: 
      https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF/resolve/main/mixtral-8x7b-moe-rp-story.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral-8x7b-moe-rp-story-gguf__mixtral-8x7b-moe-rp-story.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - not-for-all-audiences
  - nsfw
  - base_model:Undi95/Mixtral-8x7B-MoE-RP-Story
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral-8x7b-moe-rp-story.Q6_K.gguf
    template:
      chat: thebloke__mixtral-8x7b-moe-rp-story-gguf
      completion: thebloke__mixtral-8x7b-moe-rp-story-gguf
  description: TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
  - filename: mixtral-8x7b-moe-rp-story.Q6_K.gguf
    sha256: 924124dd1588294a4e3d50d0e8c200d7c9724f6df96c03afdd7b912c49f75022
    uri: 
      https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF/resolve/main/mixtral-8x7b-moe-rp-story.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral-8x7b-moe-rp-story-gguf__mixtral-8x7b-moe-rp-story.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - not-for-all-audiences
  - nsfw
  - base_model:Undi95/Mixtral-8x7B-MoE-RP-Story
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtral-8x7b-moe-rp-story.Q8_0.gguf
    template:
      chat: thebloke__mixtral-8x7b-moe-rp-story-gguf
      completion: thebloke__mixtral-8x7b-moe-rp-story-gguf
  description: TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtral-8x7b-moe-rp-story-gguf.tmpl
  - filename: mixtral-8x7b-moe-rp-story.Q8_0.gguf
    sha256: 7fdbad41ac9500de1aadc61db60943048379e9af22aba2aacd038f6682aa628c
    uri: 
      https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF/resolve/main/mixtral-8x7b-moe-rp-story.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtral-8x7b-moe-rp-story-gguf__mixtral-8x7b-moe-rp-story.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - not-for-all-audiences
  - nsfw
  - base_model:Undi95/Mixtral-8x7B-MoE-RP-Story
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Mixtral-8x7B-MoE-RP-Story-GGUF
