- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q2_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q2_K.gguf
    sha256: e3da9852fd30cba5a1c8d2826ebe75f509216657ccee7d72e6cfe0433c374d32
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_L.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_L.gguf
    sha256: d0adb39488347da76d8b0f7a5fe5b4edd16385c6cb1f10c8c873a41273a9dd58
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_M.gguf
    sha256: ace29609399e58a96b7e9eaffa7b1d34aa750be841caf763d48740d5a6d4a9e0
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_S.gguf
    sha256: db163ae8496e248bba3476d6fdcf26ba872927bd2d3f014534a21ab0e64cb9e5
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_0.gguf
    sha256: 90eff224eaa2c7cac291185c873c263d57d03237601b863df6285304d2cceb94
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_K_M.gguf
    sha256: 0b0e183ba927a161acbdebc06174b42ba3d91f6ab8d280dbb7052cf36bb79815
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_K_S.gguf
    sha256: 04da8556eb841f6f771315f679789bb9c4053267a4df2587515798c308d21f7b
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_0.gguf
    sha256: 12eda122a6eb34b932e31eda282a3fc58a5a6aef6e21d5c2df316e686adf1d98
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_K_M.gguf
    sha256: 91bb40b4dde803308c534182769b7bfc3e8764808322e9987f685174a57f0ee2
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_K_S.gguf
    sha256: 4cb265ea1caf380d4ca91a99926ce1cda888c64429ee24e8808d08dccfc9943f
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q6_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q6_K.gguf
    sha256: da7e5c2889e0d32a068aa395b8a8654eca8d016f276b7a8927029fd7fbb11ab5
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q8_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q8_0.gguf
    sha256: 88ceb08732ff79b1831fc3a3f09d4e459ba49752682619a9c840f15d4f06e224
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q2_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q2_K.gguf
    sha256: e3da9852fd30cba5a1c8d2826ebe75f509216657ccee7d72e6cfe0433c374d32
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_L.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_L.gguf
    sha256: d0adb39488347da76d8b0f7a5fe5b4edd16385c6cb1f10c8c873a41273a9dd58
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_M.gguf
    sha256: ace29609399e58a96b7e9eaffa7b1d34aa750be841caf763d48740d5a6d4a9e0
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_S.gguf
    sha256: db163ae8496e248bba3476d6fdcf26ba872927bd2d3f014534a21ab0e64cb9e5
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_0.gguf
    sha256: 90eff224eaa2c7cac291185c873c263d57d03237601b863df6285304d2cceb94
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_K_M.gguf
    sha256: 0b0e183ba927a161acbdebc06174b42ba3d91f6ab8d280dbb7052cf36bb79815
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_K_S.gguf
    sha256: 04da8556eb841f6f771315f679789bb9c4053267a4df2587515798c308d21f7b
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_0.gguf
    sha256: 12eda122a6eb34b932e31eda282a3fc58a5a6aef6e21d5c2df316e686adf1d98
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_K_M.gguf
    sha256: 91bb40b4dde803308c534182769b7bfc3e8764808322e9987f685174a57f0ee2
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_K_S.gguf
    sha256: 4cb265ea1caf380d4ca91a99926ce1cda888c64429ee24e8808d08dccfc9943f
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q6_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q6_K.gguf
    sha256: da7e5c2889e0d32a068aa395b8a8654eca8d016f276b7a8927029fd7fbb11ab5
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q8_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q8_0.gguf
    sha256: 88ceb08732ff79b1831fc3a3f09d4e459ba49752682619a9c840f15d4f06e224
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q2_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q2_K.gguf
    sha256: e3da9852fd30cba5a1c8d2826ebe75f509216657ccee7d72e6cfe0433c374d32
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_L.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_L.gguf
    sha256: d0adb39488347da76d8b0f7a5fe5b4edd16385c6cb1f10c8c873a41273a9dd58
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_M.gguf
    sha256: ace29609399e58a96b7e9eaffa7b1d34aa750be841caf763d48740d5a6d4a9e0
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q3_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q3_K_S.gguf
    sha256: db163ae8496e248bba3476d6fdcf26ba872927bd2d3f014534a21ab0e64cb9e5
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_0.gguf
    sha256: 90eff224eaa2c7cac291185c873c263d57d03237601b863df6285304d2cceb94
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_K_M.gguf
    sha256: 0b0e183ba927a161acbdebc06174b42ba3d91f6ab8d280dbb7052cf36bb79815
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q4_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q4_K_S.gguf
    sha256: 04da8556eb841f6f771315f679789bb9c4053267a4df2587515798c308d21f7b
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_0.gguf
    sha256: 12eda122a6eb34b932e31eda282a3fc58a5a6aef6e21d5c2df316e686adf1d98
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_K_M.gguf
    sha256: 91bb40b4dde803308c534182769b7bfc3e8764808322e9987f685174a57f0ee2
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q5_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q5_K_S.gguf
    sha256: 4cb265ea1caf380d4ca91a99926ce1cda888c64429ee24e8808d08dccfc9943f
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q6_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q6_K.gguf
    sha256: da7e5c2889e0d32a068aa395b8a8654eca8d016f276b7a8927029fd7fbb11ab5
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-v2-13b.Q8_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/Kimiko-v2-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: kimiko-v2-13b.Q8_0.gguf
    sha256: 88ceb08732ff79b1831fc3a3f09d4e459ba49752682619a9c840f15d4f06e224
    uri: 
      https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF/resolve/main/kimiko-v2-13b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: creativeml-openrail-m
  name: thebloke__kimiko-v2-13b-gguf__kimiko-v2-13b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - text-generation
  - en
  - base_model:nRuaif/Kimiko-v2-13B
  - license:creativeml-openrail-m
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-v2-13B-GGUF
