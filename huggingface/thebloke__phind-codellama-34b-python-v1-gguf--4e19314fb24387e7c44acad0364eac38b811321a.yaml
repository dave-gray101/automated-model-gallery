- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q2_K.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q2_K.gguf
    sha256: 0ebf4ded35204248dec791f2fd1757516887e24e79463668ca15bf5d2848d196
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q3_K_L.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q3_K_L.gguf
    sha256: 9d191da2cced838c6364567a418a4bec0e6bc00c3c2efd88bdd1e76c397711a4
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q3_K_M.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q3_K_M.gguf
    sha256: d8c35f574634d3878d20fef73dff407bfab73e35b48487b3801937eff3a2e4e2
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q3_K_S.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q3_K_S.gguf
    sha256: bc7a9cdafe17cfd5076284ea4324f194302b4ca4c3a0bf021804cd238fa07bc7
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q4_0.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q4_0.gguf
    sha256: beeba5b770c7244aa9f6811eb97c34155cddd57297c647693731d79aac9ef3fb
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q4_K_M.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q4_K_M.gguf
    sha256: 74d7387eb39541af895600f2a0143d6c0b6fea97ba4fc03cd07a7daa80315930
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q4_K_S.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q4_K_S.gguf
    sha256: 92200c80e0e5fb2c65d79cbafbc2532fb0e1958cd62e60d3b149f81c7cbf128f
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q5_0.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q5_0.gguf
    sha256: 4432ee5648b934225af3a7a9938429f3fa8b284f0291985f9fcfffcc19f8c5d0
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q5_K_M.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q5_K_M.gguf
    sha256: 9f41e4aa21b58fcac74686562ffa929d5ba489f3b58cc226639c3103803888f9
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q5_K_S.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q5_K_S.gguf
    sha256: fb1cc8bbcd051f095a7be7f60b4aee47806f34fe35c3fa23f05e8fefb95c22fb
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q6_K.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q6_K.gguf
    sha256: 4b1217162b1ee4a96a29e9ad1b2ddc925c15b16af5f18c02d441e8d84993a3a1
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q8_0.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llama configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q8_0.gguf
    sha256: 8d8a91abbc8f98c8d95fd472bd3a6af58534be13d9570dbf8c0145dbefcfd46f
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q2_K.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q2_K.gguf
    sha256: 0ebf4ded35204248dec791f2fd1757516887e24e79463668ca15bf5d2848d196
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q3_K_L.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q3_K_L.gguf
    sha256: 9d191da2cced838c6364567a418a4bec0e6bc00c3c2efd88bdd1e76c397711a4
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q3_K_M.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q3_K_M.gguf
    sha256: d8c35f574634d3878d20fef73dff407bfab73e35b48487b3801937eff3a2e4e2
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q3_K_S.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q3_K_S.gguf
    sha256: bc7a9cdafe17cfd5076284ea4324f194302b4ca4c3a0bf021804cd238fa07bc7
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q4_0.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q4_0.gguf
    sha256: beeba5b770c7244aa9f6811eb97c34155cddd57297c647693731d79aac9ef3fb
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q4_K_M.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q4_K_M.gguf
    sha256: 74d7387eb39541af895600f2a0143d6c0b6fea97ba4fc03cd07a7daa80315930
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q4_K_S.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q4_K_S.gguf
    sha256: 92200c80e0e5fb2c65d79cbafbc2532fb0e1958cd62e60d3b149f81c7cbf128f
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q5_0.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q5_0.gguf
    sha256: 4432ee5648b934225af3a7a9938429f3fa8b284f0291985f9fcfffcc19f8c5d0
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q5_K_M.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q5_K_M.gguf
    sha256: 9f41e4aa21b58fcac74686562ffa929d5ba489f3b58cc226639c3103803888f9
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q5_K_S.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q5_K_S.gguf
    sha256: fb1cc8bbcd051f095a7be7f60b4aee47806f34fe35c3fa23f05e8fefb95c22fb
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q6_K.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q6_K.gguf
    sha256: 4b1217162b1ee4a96a29e9ad1b2ddc925c15b16af5f18c02d441e8d84993a3a1
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: phind-codellama-34b-python-v1.Q8_0.gguf
    template:
      chat: plain-with-newline
      completion: plain-with-newline
  description: TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF - llamaFileFormatFallback
    configuration
  files:
  - filename: plain-with-newline.tmpl
    sha256: 4f0d98758be1c3d4f9c88a8373b4e71cdddd5f9a3dab254f9cd8b15a9d822d0d
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/plain-with-newline.tmpl
  - filename: phind-codellama-34b-python-v1.Q8_0.gguf
    sha256: 8d8a91abbc8f98c8d95fd472bd3a6af58534be13d9570dbf8c0145dbefcfd46f
    uri: 
      https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF/resolve/main/phind-codellama-34b-python-v1.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: 
    thebloke__phind-codellama-34b-python-v1-gguf__phind-codellama-34b-python-v1.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - code llama
  - base_model:Phind/Phind-CodeLlama-34B-Python-v1
  - license:llama2
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF
