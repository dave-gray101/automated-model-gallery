- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: firefly-mixtral-8x7b.Q2_K.gguf
    template:
      chat: thebloke__firefly-mixtral-8x7b-gguf
      completion: thebloke__firefly-mixtral-8x7b-gguf
  description: TheBloke/firefly-mixtral-8x7b-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__firefly-mixtral-8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__firefly-mixtral-8x7b-gguf.tmpl
  - filename: firefly-mixtral-8x7b.Q2_K.gguf
    sha256: caa2ecb2eefaee42eb3d5a4e55826b722fc3122737b165ae612a2d703d9e277b
    uri: 
      https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF/resolve/main/firefly-mixtral-8x7b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__firefly-mixtral-8x7b-gguf__firefly-mixtral-8x7b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - en
  - base_model:YeungNLP/firefly-mixtral-8x7b
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: firefly-mixtral-8x7b.Q3_K_M.gguf
    template:
      chat: thebloke__firefly-mixtral-8x7b-gguf
      completion: thebloke__firefly-mixtral-8x7b-gguf
  description: TheBloke/firefly-mixtral-8x7b-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__firefly-mixtral-8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__firefly-mixtral-8x7b-gguf.tmpl
  - filename: firefly-mixtral-8x7b.Q3_K_M.gguf
    sha256: 4519872ee7200475d500cb73a01f4ae243654dbe3df9f98f3a91327a28af834a
    uri: 
      https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF/resolve/main/firefly-mixtral-8x7b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__firefly-mixtral-8x7b-gguf__firefly-mixtral-8x7b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - en
  - base_model:YeungNLP/firefly-mixtral-8x7b
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: firefly-mixtral-8x7b.Q4_0.gguf
    template:
      chat: thebloke__firefly-mixtral-8x7b-gguf
      completion: thebloke__firefly-mixtral-8x7b-gguf
  description: TheBloke/firefly-mixtral-8x7b-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__firefly-mixtral-8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__firefly-mixtral-8x7b-gguf.tmpl
  - filename: firefly-mixtral-8x7b.Q4_0.gguf
    sha256: 46a1a2cfbf7168f85a8599028c4699a2ba36d44a73021712718875baf0559937
    uri: 
      https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF/resolve/main/firefly-mixtral-8x7b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__firefly-mixtral-8x7b-gguf__firefly-mixtral-8x7b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - en
  - base_model:YeungNLP/firefly-mixtral-8x7b
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: firefly-mixtral-8x7b.Q4_K_M.gguf
    template:
      chat: thebloke__firefly-mixtral-8x7b-gguf
      completion: thebloke__firefly-mixtral-8x7b-gguf
  description: TheBloke/firefly-mixtral-8x7b-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__firefly-mixtral-8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__firefly-mixtral-8x7b-gguf.tmpl
  - filename: firefly-mixtral-8x7b.Q4_K_M.gguf
    sha256: dd41e0cf28733191a8fb05df3055c065521738962f926da5b5963959e3bd7e1b
    uri: 
      https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF/resolve/main/firefly-mixtral-8x7b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__firefly-mixtral-8x7b-gguf__firefly-mixtral-8x7b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - en
  - base_model:YeungNLP/firefly-mixtral-8x7b
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: firefly-mixtral-8x7b.Q5_0.gguf
    template:
      chat: thebloke__firefly-mixtral-8x7b-gguf
      completion: thebloke__firefly-mixtral-8x7b-gguf
  description: TheBloke/firefly-mixtral-8x7b-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__firefly-mixtral-8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__firefly-mixtral-8x7b-gguf.tmpl
  - filename: firefly-mixtral-8x7b.Q5_0.gguf
    sha256: 9272334886929f331407aa509eea566008ca58683616a6a6aa03bffe64c45a18
    uri: 
      https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF/resolve/main/firefly-mixtral-8x7b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__firefly-mixtral-8x7b-gguf__firefly-mixtral-8x7b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - en
  - base_model:YeungNLP/firefly-mixtral-8x7b
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: firefly-mixtral-8x7b.Q5_K_M.gguf
    template:
      chat: thebloke__firefly-mixtral-8x7b-gguf
      completion: thebloke__firefly-mixtral-8x7b-gguf
  description: TheBloke/firefly-mixtral-8x7b-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__firefly-mixtral-8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__firefly-mixtral-8x7b-gguf.tmpl
  - filename: firefly-mixtral-8x7b.Q5_K_M.gguf
    sha256: c85e9a360953af32d781a832d935c9131eb6e890d8c3e7ecee7dd679e8644950
    uri: 
      https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF/resolve/main/firefly-mixtral-8x7b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__firefly-mixtral-8x7b-gguf__firefly-mixtral-8x7b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - en
  - base_model:YeungNLP/firefly-mixtral-8x7b
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: firefly-mixtral-8x7b.Q6_K.gguf
    template:
      chat: thebloke__firefly-mixtral-8x7b-gguf
      completion: thebloke__firefly-mixtral-8x7b-gguf
  description: TheBloke/firefly-mixtral-8x7b-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__firefly-mixtral-8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__firefly-mixtral-8x7b-gguf.tmpl
  - filename: firefly-mixtral-8x7b.Q6_K.gguf
    sha256: e2906987328134b022eb3cb18ddc121624722ca955e740b1144fca30b1d79188
    uri: 
      https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF/resolve/main/firefly-mixtral-8x7b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__firefly-mixtral-8x7b-gguf__firefly-mixtral-8x7b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - en
  - base_model:YeungNLP/firefly-mixtral-8x7b
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: firefly-mixtral-8x7b.Q8_0.gguf
    template:
      chat: thebloke__firefly-mixtral-8x7b-gguf
      completion: thebloke__firefly-mixtral-8x7b-gguf
  description: TheBloke/firefly-mixtral-8x7b-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__firefly-mixtral-8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__firefly-mixtral-8x7b-gguf.tmpl
  - filename: firefly-mixtral-8x7b.Q8_0.gguf
    sha256: a4d28e9fb5f5adebd4797c3598e645b31ab35daf584e842a710882a0900a0470
    uri: 
      https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF/resolve/main/firefly-mixtral-8x7b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: thebloke__firefly-mixtral-8x7b-gguf__firefly-mixtral-8x7b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - en
  - base_model:YeungNLP/firefly-mixtral-8x7b
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/firefly-mixtral-8x7b-GGUF
