- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtralorochi8x7b.Q2_K.gguf
    template:
      chat: thebloke__mixtralorochi8x7b-gguf
      completion: thebloke__mixtralorochi8x7b-gguf
  description: TheBloke/MixtralOrochi8x7B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtralorochi8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtralorochi8x7b-gguf.tmpl
  - filename: mixtralorochi8x7b.Q2_K.gguf
    sha256: e4297cdf7f10cb18bc362e4584fb761ddf6464e3bc93bdd3ad804416831065ee
    uri: 
      https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF/resolve/main/mixtralorochi8x7b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtralorochi8x7b-gguf__mixtralorochi8x7b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - uncensored
  - high-intelligence
  - en
  - base_model:smelborp/MixtralOrochi8x7B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtralorochi8x7b.Q3_K_M.gguf
    template:
      chat: thebloke__mixtralorochi8x7b-gguf
      completion: thebloke__mixtralorochi8x7b-gguf
  description: TheBloke/MixtralOrochi8x7B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtralorochi8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtralorochi8x7b-gguf.tmpl
  - filename: mixtralorochi8x7b.Q3_K_M.gguf
    sha256: 995aaadb40b4baf700626591cc007d5cf9380a4cda52ac995e82cf6297b7293a
    uri: 
      https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF/resolve/main/mixtralorochi8x7b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtralorochi8x7b-gguf__mixtralorochi8x7b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - uncensored
  - high-intelligence
  - en
  - base_model:smelborp/MixtralOrochi8x7B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtralorochi8x7b.Q4_0.gguf
    template:
      chat: thebloke__mixtralorochi8x7b-gguf
      completion: thebloke__mixtralorochi8x7b-gguf
  description: TheBloke/MixtralOrochi8x7B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtralorochi8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtralorochi8x7b-gguf.tmpl
  - filename: mixtralorochi8x7b.Q4_0.gguf
    sha256: b1371b22a02f6687d403b49d0c9175a811ef546cc402d0e09e1d27762cac9de4
    uri: 
      https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF/resolve/main/mixtralorochi8x7b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtralorochi8x7b-gguf__mixtralorochi8x7b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - uncensored
  - high-intelligence
  - en
  - base_model:smelborp/MixtralOrochi8x7B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtralorochi8x7b.Q4_K_M.gguf
    template:
      chat: thebloke__mixtralorochi8x7b-gguf
      completion: thebloke__mixtralorochi8x7b-gguf
  description: TheBloke/MixtralOrochi8x7B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtralorochi8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtralorochi8x7b-gguf.tmpl
  - filename: mixtralorochi8x7b.Q4_K_M.gguf
    sha256: a8f4e8a272b5ce2487777906205f8db492df330ec5583e993d95ca5fd51e5e7c
    uri: 
      https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF/resolve/main/mixtralorochi8x7b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtralorochi8x7b-gguf__mixtralorochi8x7b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - uncensored
  - high-intelligence
  - en
  - base_model:smelborp/MixtralOrochi8x7B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtralorochi8x7b.Q5_0.gguf
    template:
      chat: thebloke__mixtralorochi8x7b-gguf
      completion: thebloke__mixtralorochi8x7b-gguf
  description: TheBloke/MixtralOrochi8x7B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtralorochi8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtralorochi8x7b-gguf.tmpl
  - filename: mixtralorochi8x7b.Q5_0.gguf
    sha256: 36857ba7d4e26b31d489544b81bf913c48bf56dca978222070ba8a3c0e051a84
    uri: 
      https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF/resolve/main/mixtralorochi8x7b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtralorochi8x7b-gguf__mixtralorochi8x7b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - uncensored
  - high-intelligence
  - en
  - base_model:smelborp/MixtralOrochi8x7B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtralorochi8x7b.Q5_K_M.gguf
    template:
      chat: thebloke__mixtralorochi8x7b-gguf
      completion: thebloke__mixtralorochi8x7b-gguf
  description: TheBloke/MixtralOrochi8x7B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtralorochi8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtralorochi8x7b-gguf.tmpl
  - filename: mixtralorochi8x7b.Q5_K_M.gguf
    sha256: 8710f592b907e1d74bb3779690203df984840131c152378f9f076e8a137ca7c3
    uri: 
      https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF/resolve/main/mixtralorochi8x7b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtralorochi8x7b-gguf__mixtralorochi8x7b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - uncensored
  - high-intelligence
  - en
  - base_model:smelborp/MixtralOrochi8x7B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtralorochi8x7b.Q6_K.gguf
    template:
      chat: thebloke__mixtralorochi8x7b-gguf
      completion: thebloke__mixtralorochi8x7b-gguf
  description: TheBloke/MixtralOrochi8x7B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtralorochi8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtralorochi8x7b-gguf.tmpl
  - filename: mixtralorochi8x7b.Q6_K.gguf
    sha256: d8ba2240d168744e76d82452ea92ee400d6267a8e83adf85d9ea228cdf7527a6
    uri: 
      https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF/resolve/main/mixtralorochi8x7b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtralorochi8x7b-gguf__mixtralorochi8x7b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - uncensored
  - high-intelligence
  - en
  - base_model:smelborp/MixtralOrochi8x7B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: mixtralorochi8x7b.Q8_0.gguf
    template:
      chat: thebloke__mixtralorochi8x7b-gguf
      completion: thebloke__mixtralorochi8x7b-gguf
  description: TheBloke/MixtralOrochi8x7B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__mixtralorochi8x7b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__mixtralorochi8x7b-gguf.tmpl
  - filename: mixtralorochi8x7b.Q8_0.gguf
    sha256: 1a548344cdea5a6a3339874103014f041b6611aa2b04634fa335c4a76791d22d
    uri: 
      https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF/resolve/main/mixtralorochi8x7b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-4.0
  name: thebloke__mixtralorochi8x7b-gguf__mixtralorochi8x7b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - mixtral
  - uncensored
  - high-intelligence
  - en
  - base_model:smelborp/MixtralOrochi8x7B
  - license:cc-by-nc-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/MixtralOrochi8x7B-GGUF
