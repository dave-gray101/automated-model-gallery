- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q2_K.gguf
    sha256: 73b298f722a8d9d789508022c2adda18f3050942a4767923162b95b0bc65b9ad
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_L.gguf
    sha256: fdbafbd68d9caee2bc2a284e2cba7ec2f69c70937e2f63d1c438ce5b62599d65
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_M.gguf
    sha256: b228769a9027e27b2098be6ca108a0b9867bc45c51f2ede8309c21e827a3ed71
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_S.gguf
    sha256: 7a4d4d3e8a9be253bf7d67c45aa7daa48fa714a6835c0eda024d4934ad92bd1a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_0.gguf
    sha256: a2f287bb96b96e3d87a96a818bd1721e57bfcae94dbcff671e77c3e601f967fe
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_K_M.gguf
    sha256: 0701500c591c2c1b910516658e58044cdfa07b2e8b5a2e3b6808d983441daf1a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_K_S.gguf
    sha256: 2e44d2b7ae28bbe3a2ed698e259cbd3a6bf7fe8f9d351e14b2be17fb690d7f95
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_0.gguf
    sha256: 272d98e40b480235d9f2f4e4ce40a57928c3c2b609545f0852ac13196dca9878
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_K_M.gguf
    sha256: 774f2a7c97db49bee66a3091d31f0c3a35d70d85f6aada65626882177a858fd7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_K_S.gguf
    sha256: 8b91b06842a3327936028fbbe04f25c22a6d608a1a7e32f27145aeb6ada306c5
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q6_K.gguf
    sha256: 2f516cd9c16181832ffceaf94b13e8600d88c9bc8d7f75717d25d8c9cf9aa973
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q8_0.gguf
    sha256: 2126a5b9e8576ebea8889792ec5e459423935daae17ac0ffdfbedb39d222a20e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q2_K.gguf
    sha256: 73b298f722a8d9d789508022c2adda18f3050942a4767923162b95b0bc65b9ad
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_L.gguf
    sha256: fdbafbd68d9caee2bc2a284e2cba7ec2f69c70937e2f63d1c438ce5b62599d65
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_M.gguf
    sha256: b228769a9027e27b2098be6ca108a0b9867bc45c51f2ede8309c21e827a3ed71
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_S.gguf
    sha256: 7a4d4d3e8a9be253bf7d67c45aa7daa48fa714a6835c0eda024d4934ad92bd1a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_0.gguf
    sha256: a2f287bb96b96e3d87a96a818bd1721e57bfcae94dbcff671e77c3e601f967fe
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_K_M.gguf
    sha256: 0701500c591c2c1b910516658e58044cdfa07b2e8b5a2e3b6808d983441daf1a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_K_S.gguf
    sha256: 2e44d2b7ae28bbe3a2ed698e259cbd3a6bf7fe8f9d351e14b2be17fb690d7f95
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_0.gguf
    sha256: 272d98e40b480235d9f2f4e4ce40a57928c3c2b609545f0852ac13196dca9878
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_K_M.gguf
    sha256: 774f2a7c97db49bee66a3091d31f0c3a35d70d85f6aada65626882177a858fd7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_K_S.gguf
    sha256: 8b91b06842a3327936028fbbe04f25c22a6d608a1a7e32f27145aeb6ada306c5
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q6_K.gguf
    sha256: 2f516cd9c16181832ffceaf94b13e8600d88c9bc8d7f75717d25d8c9cf9aa973
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q8_0.gguf
    sha256: 2126a5b9e8576ebea8889792ec5e459423935daae17ac0ffdfbedb39d222a20e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q2_K.gguf
    sha256: 73b298f722a8d9d789508022c2adda18f3050942a4767923162b95b0bc65b9ad
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_L.gguf
    sha256: fdbafbd68d9caee2bc2a284e2cba7ec2f69c70937e2f63d1c438ce5b62599d65
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_M.gguf
    sha256: b228769a9027e27b2098be6ca108a0b9867bc45c51f2ede8309c21e827a3ed71
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q3_K_S.gguf
    sha256: 7a4d4d3e8a9be253bf7d67c45aa7daa48fa714a6835c0eda024d4934ad92bd1a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_0.gguf
    sha256: a2f287bb96b96e3d87a96a818bd1721e57bfcae94dbcff671e77c3e601f967fe
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_K_M.gguf
    sha256: 0701500c591c2c1b910516658e58044cdfa07b2e8b5a2e3b6808d983441daf1a
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q4_K_S.gguf
    sha256: 2e44d2b7ae28bbe3a2ed698e259cbd3a6bf7fe8f9d351e14b2be17fb690d7f95
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_0.gguf
    sha256: 272d98e40b480235d9f2f4e4ce40a57928c3c2b609545f0852ac13196dca9878
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_K_M.gguf
    sha256: 774f2a7c97db49bee66a3091d31f0c3a35d70d85f6aada65626882177a858fd7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q5_K_S.gguf
    sha256: 8b91b06842a3327936028fbbe04f25c22a6d608a1a7e32f27145aeb6ada306c5
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q6_K.gguf
    sha256: 2f516cd9c16181832ffceaf94b13e8600d88c9bc8d7f75717d25d8c9cf9aa973
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-instruct.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Instruct-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-instruct.Q8_0.gguf
    sha256: 2126a5b9e8576ebea8889792ec5e459423935daae17ac0ffdfbedb39d222a20e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-instruct-gguf__codellama-7b-instruct.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-instruct-hf
  - license:llama2
  - has_space
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF
