- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q2_K.gguf
    sha256: 982276bcef3ebdde355a4fd57df3ffb7fdab2424655933e198224835b82aef6e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_L.gguf
    sha256: d33d53d4f36029b9570b0265167cfe01009afb73f29284bd613199a6dafeb539
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_M.gguf
    sha256: dd6225622c6bb94b760a1c1880bcb4cc0c9dd33e2c7a18bfc20de547670ff836
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_S.gguf
    sha256: 4bb3826a2162f248246ce15ae7eada5efb7750dd391460141929981d4a3c7fb8
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_0.gguf
    sha256: 51d750ad6abaa4b2a8a21f2e7ad6df9b34bf48b82cf3191215bd0e3d990e3624
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_K_M.gguf
    sha256: a623f4cd1dd5c68235d02683a3d92d0154dfd174df58e6cb05b3bc55befa4fc8
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_K_S.gguf
    sha256: 4d53e629b10c621da0a73d97fd17f66721a3cfb22e5484b9212c2c6ec5ad2c57
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_0.gguf
    sha256: 562a3fbf0b538f6144ab6931be3fb1c074c6e59bbb8707bbc8fe6731385489dd
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_K_M.gguf
    sha256: 8f9c248e3e3868df702143f8a28e0c2dd52ee0ce27366af2c4fffd8476f4001f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_K_S.gguf
    sha256: d13f076f3b12228a41306707fabab45a57d3517f32ea0580eff9e86b046c1551
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q6_K.gguf
    sha256: f54749752a3bdbdff28b4668c52e480be6a4a969e976fcc6ca426781f07a8878
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llama configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q8_0.gguf
    sha256: 4e3134ec4d544d1c3296cdc4bfecb230211e93c736c46e3daefdab21c13b17b9
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q2_K.gguf
    sha256: 982276bcef3ebdde355a4fd57df3ffb7fdab2424655933e198224835b82aef6e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_L.gguf
    sha256: d33d53d4f36029b9570b0265167cfe01009afb73f29284bd613199a6dafeb539
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_M.gguf
    sha256: dd6225622c6bb94b760a1c1880bcb4cc0c9dd33e2c7a18bfc20de547670ff836
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_S.gguf
    sha256: 4bb3826a2162f248246ce15ae7eada5efb7750dd391460141929981d4a3c7fb8
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_0.gguf
    sha256: 51d750ad6abaa4b2a8a21f2e7ad6df9b34bf48b82cf3191215bd0e3d990e3624
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_K_M.gguf
    sha256: a623f4cd1dd5c68235d02683a3d92d0154dfd174df58e6cb05b3bc55befa4fc8
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_K_S.gguf
    sha256: 4d53e629b10c621da0a73d97fd17f66721a3cfb22e5484b9212c2c6ec5ad2c57
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_0.gguf
    sha256: 562a3fbf0b538f6144ab6931be3fb1c074c6e59bbb8707bbc8fe6731385489dd
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_K_M.gguf
    sha256: 8f9c248e3e3868df702143f8a28e0c2dd52ee0ce27366af2c4fffd8476f4001f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_K_S.gguf
    sha256: d13f076f3b12228a41306707fabab45a57d3517f32ea0580eff9e86b046c1551
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q6_K.gguf
    sha256: f54749752a3bdbdff28b4668c52e480be6a4a969e976fcc6ca426781f07a8878
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q8_0.gguf
    sha256: 4e3134ec4d544d1c3296cdc4bfecb230211e93c736c46e3daefdab21c13b17b9
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q2_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q2_K.gguf
    sha256: 982276bcef3ebdde355a4fd57df3ffb7fdab2424655933e198224835b82aef6e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_L.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_L.gguf
    sha256: d33d53d4f36029b9570b0265167cfe01009afb73f29284bd613199a6dafeb539
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_M.gguf
    sha256: dd6225622c6bb94b760a1c1880bcb4cc0c9dd33e2c7a18bfc20de547670ff836
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q3_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q3_K_S.gguf
    sha256: 4bb3826a2162f248246ce15ae7eada5efb7750dd391460141929981d4a3c7fb8
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_0.gguf
    sha256: 51d750ad6abaa4b2a8a21f2e7ad6df9b34bf48b82cf3191215bd0e3d990e3624
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_K_M.gguf
    sha256: a623f4cd1dd5c68235d02683a3d92d0154dfd174df58e6cb05b3bc55befa4fc8
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q4_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q4_K_S.gguf
    sha256: 4d53e629b10c621da0a73d97fd17f66721a3cfb22e5484b9212c2c6ec5ad2c57
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_0.gguf
    sha256: 562a3fbf0b538f6144ab6931be3fb1c074c6e59bbb8707bbc8fe6731385489dd
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_K_M.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_K_M.gguf
    sha256: 8f9c248e3e3868df702143f8a28e0c2dd52ee0ce27366af2c4fffd8476f4001f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q5_K_S.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q5_K_S.gguf
    sha256: d13f076f3b12228a41306707fabab45a57d3517f32ea0580eff9e86b046c1551
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q6_K.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q6_K.gguf
    sha256: f54749752a3bdbdff28b4668c52e480be6a4a969e976fcc6ca426781f07a8878
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-7b-python.Q8_0.gguf
    template:
      chat: codellama
      completion: codellama
  description: TheBloke/CodeLlama-7B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: codellama.tmpl
    sha256: b9356ff6dd41a49dcac2425cc7d9c6503d5312d2746c7a041c101bda0b9e4399
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/codellama.tmpl
  - filename: codellama-7b-python.Q8_0.gguf
    sha256: 4e3134ec4d544d1c3296cdc4bfecb230211e93c736c46e3daefdab21c13b17b9
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF/resolve/main/codellama-7b-python.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-7b-python-gguf__codellama-7b-python.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-7b-python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-7B-Python-GGUF
