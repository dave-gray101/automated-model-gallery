- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q2_K.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q2_K.gguf
    sha256: 9ce6853574e3b3029b332d3fea93b60d42d06a23b035f75ee86663f41918f7ae
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q3_K_L.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q3_K_L.gguf
    sha256: a2ff5bfa320e8023f8ae015f13161f534d8c5d227ae5669b967316e6d1352d91
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q3_K_M.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q3_K_M.gguf
    sha256: 41cc8ecfb76eecc3654361041b22d73367f773868c3a9507fe4da6b54ef70b99
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q3_K_S.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q3_K_S.gguf
    sha256: 8eba5f0214a143ed68c496bbaa35095dcd90bd04db8385db6797b76993854046
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q4_0.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q4_0.gguf
    sha256: 1a286b42a97ec69189f9186302345d97d7e4e430f741ec6ca4e5b13594140fe6
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q4_K_M.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q4_K_M.gguf
    sha256: 58cf8933eae5d163a50742a7b00e6b505413cab3cf4a624558619394328f83cb
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q4_K_S.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q4_K_S.gguf
    sha256: f8c4453f1134a9a4e2bc442400c46576982da407542966efdf256f61bf220890
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q5_0.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q5_0.gguf
    sha256: 4671158ba8c2bc8ef89518063b7dc5e88faf4951023f90d7e8f313a75651acae
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q5_K_M.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q5_K_M.gguf
    sha256: 1aedab672442291ef98e63123ab32f1506e7a77a5a5d4c28f7560e90a62a4bcc
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q5_K_S.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q5_K_S.gguf
    sha256: b6f77d1511ecb4946a82cd1489988aec201d7c7a8607f9bd17a35c18480faf73
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q6_K.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q6_K.gguf
    sha256: 57704f9c04215aa3aa35a877580c449abe96f42f3e3291cfd7c76b10d8ca5d08
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q8_0.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llama configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q8_0.gguf
    sha256: 4f1804d8b4bc25cec5f872e39a23e2835646378854b55620c8cc07fd66e25f4c
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q2_K.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q2_K.gguf
    sha256: 9ce6853574e3b3029b332d3fea93b60d42d06a23b035f75ee86663f41918f7ae
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q3_K_L.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q3_K_L.gguf
    sha256: a2ff5bfa320e8023f8ae015f13161f534d8c5d227ae5669b967316e6d1352d91
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q3_K_M.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q3_K_M.gguf
    sha256: 41cc8ecfb76eecc3654361041b22d73367f773868c3a9507fe4da6b54ef70b99
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q3_K_S.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q3_K_S.gguf
    sha256: 8eba5f0214a143ed68c496bbaa35095dcd90bd04db8385db6797b76993854046
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q4_0.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q4_0.gguf
    sha256: 1a286b42a97ec69189f9186302345d97d7e4e430f741ec6ca4e5b13594140fe6
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q4_K_M.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q4_K_M.gguf
    sha256: 58cf8933eae5d163a50742a7b00e6b505413cab3cf4a624558619394328f83cb
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q4_K_S.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q4_K_S.gguf
    sha256: f8c4453f1134a9a4e2bc442400c46576982da407542966efdf256f61bf220890
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q5_0.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q5_0.gguf
    sha256: 4671158ba8c2bc8ef89518063b7dc5e88faf4951023f90d7e8f313a75651acae
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q5_K_M.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q5_K_M.gguf
    sha256: 1aedab672442291ef98e63123ab32f1506e7a77a5a5d4c28f7560e90a62a4bcc
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q5_K_S.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q5_K_S.gguf
    sha256: b6f77d1511ecb4946a82cd1489988aec201d7c7a8607f9bd17a35c18480faf73
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q6_K.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q6_K.gguf
    sha256: 57704f9c04215aa3aa35a877580c449abe96f42f3e3291cfd7c76b10d8ca5d08
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: nucleus-22b-token-500b.Q8_0.gguf
    template:
      chat: thebloke__nucleus-22b-token-500b-gguf
      completion: thebloke__nucleus-22b-token-500b-gguf
  description: TheBloke/nucleus-22B-token-500B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__nucleus-22b-token-500b-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__nucleus-22b-token-500b-gguf.tmpl
  - filename: nucleus-22b-token-500b.Q8_0.gguf
    sha256: 4f1804d8b4bc25cec5f872e39a23e2835646378854b55620c8cc07fd66e25f4c
    uri: 
      https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF/resolve/main/nucleus-22b-token-500b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: mit
  name: thebloke__nucleus-22b-token-500b-gguf__nucleus-22b-token-500b.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - en
  - base_model:NucleusAI/nucleus-22B-token-500B
  - license:mit
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/nucleus-22B-token-500B-GGUF
