- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q2_K.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q2_K.gguf
    sha256: c624c964d0de324323ae9387f9cf4aaf33d8536ea4b90a63c61c347f48ed84e0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_L.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_L.gguf
    sha256: 26c67451e8981292039e1e6987ef6d908cab605add9354c16cde45818e31f6e7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_M.gguf
    sha256: f52bb603be241d850dec4868ee8a7ee0943d771f8fc32454afcc50fc07924cf6
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_S.gguf
    sha256: 235ca5d467d453bb71dcffd7fb544e5d5560717865cb1c019ae842017a95af5b
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_0.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_0.gguf
    sha256: a6884199f677eb829ad2b384b108c14219bba7f2f2f85e13096201cae904b99e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_K_M.gguf
    sha256: 043fddc12e2ef78bfbed52e12bd94cd8a644e912b15915b57ad79e0b81e12aea
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_K_S.gguf
    sha256: 5cb97ea91a974990f9a0604d9c4d9e76f9a8b75805504157cdb04b3147b79b21
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_0.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_0.gguf
    sha256: e7b0dc572406bca88eb78f6ca2431924f88598d5ffed6ef06b07c80dc14b9e85
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_K_M.gguf
    sha256: b4904a3b9db599ea9937618c9a1a2d0d9cdce4125fa21b2e62e4f835d582f34e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llama configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_K_S.gguf
    sha256: 5837c5ecfa426c00577c5b6dd2915950147d5659abfa1bc65ad0045b3723d217
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q2_K.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q2_K.gguf
    sha256: c624c964d0de324323ae9387f9cf4aaf33d8536ea4b90a63c61c347f48ed84e0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_L.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_L.gguf
    sha256: 26c67451e8981292039e1e6987ef6d908cab605add9354c16cde45818e31f6e7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_M.gguf
    sha256: f52bb603be241d850dec4868ee8a7ee0943d771f8fc32454afcc50fc07924cf6
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_S.gguf
    sha256: 235ca5d467d453bb71dcffd7fb544e5d5560717865cb1c019ae842017a95af5b
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_0.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_0.gguf
    sha256: a6884199f677eb829ad2b384b108c14219bba7f2f2f85e13096201cae904b99e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_K_M.gguf
    sha256: 043fddc12e2ef78bfbed52e12bd94cd8a644e912b15915b57ad79e0b81e12aea
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_K_S.gguf
    sha256: 5cb97ea91a974990f9a0604d9c4d9e76f9a8b75805504157cdb04b3147b79b21
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_0.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_0.gguf
    sha256: e7b0dc572406bca88eb78f6ca2431924f88598d5ffed6ef06b07c80dc14b9e85
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_K_M.gguf
    sha256: b4904a3b9db599ea9937618c9a1a2d0d9cdce4125fa21b2e62e4f835d582f34e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_K_S.gguf
    sha256: 5837c5ecfa426c00577c5b6dd2915950147d5659abfa1bc65ad0045b3723d217
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q2_K.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q2_K.gguf
    sha256: c624c964d0de324323ae9387f9cf4aaf33d8536ea4b90a63c61c347f48ed84e0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_L.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_L.gguf
    sha256: 26c67451e8981292039e1e6987ef6d908cab605add9354c16cde45818e31f6e7
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_M.gguf
    sha256: f52bb603be241d850dec4868ee8a7ee0943d771f8fc32454afcc50fc07924cf6
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q3_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q3_K_S.gguf
    sha256: 235ca5d467d453bb71dcffd7fb544e5d5560717865cb1c019ae842017a95af5b
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_0.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_0.gguf
    sha256: a6884199f677eb829ad2b384b108c14219bba7f2f2f85e13096201cae904b99e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_K_M.gguf
    sha256: 043fddc12e2ef78bfbed52e12bd94cd8a644e912b15915b57ad79e0b81e12aea
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q4_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q4_K_S.gguf
    sha256: 5cb97ea91a974990f9a0604d9c4d9e76f9a8b75805504157cdb04b3147b79b21
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_0.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_0.gguf
    sha256: e7b0dc572406bca88eb78f6ca2431924f88598d5ffed6ef06b07c80dc14b9e85
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_K_M.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_K_M.gguf
    sha256: b4904a3b9db599ea9937618c9a1a2d0d9cdce4125fa21b2e62e4f835d582f34e
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-70b-python.Q5_K_S.gguf
    template:
      chat: thebloke__codellama-70b-python-gguf
      completion: thebloke__codellama-70b-python-gguf
  description: TheBloke/CodeLlama-70B-Python-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: thebloke__codellama-70b-python-gguf.tmpl
    sha256: e1a2961994016082e8bd585199ff1e1dc0e8ef2b1596da49b38cc99785321e22
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/thebloke__codellama-70b-python-gguf.tmpl
  - filename: codellama-70b-python.Q5_K_S.gguf
    sha256: 5837c5ecfa426c00577c5b6dd2915950147d5659abfa1bc65ad0045b3723d217
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF/resolve/main/codellama-70b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__codellama-70b-python-gguf__codellama-70b-python.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - base_model:codellama/CodeLlama-70b-Python-hf
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-70B-Python-GGUF
