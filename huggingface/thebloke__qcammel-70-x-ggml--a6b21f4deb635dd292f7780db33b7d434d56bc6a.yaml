- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q2_K.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q2_K.bin
    sha256: d72768935527942c22cd48b36bc91600697c8384a458be6d6aa2d414e24826eb
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q2_K.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_L.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_L.bin
    sha256: 340f5b3f1968c93ed70c6c3be84011fc72bb19c15869abe13fb5879448cf88a4
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_L.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_M.bin
    sha256: 1ef4e22b579be5a0bd78191979f9d07516c42c9b8ec8467a99ee803d461d89a7
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_S.bin
    sha256: ae4f3741ef5d20cbcac8d844c8c0d4964d1128ff3dd85c7ff2f235f495e25827
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_0.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_0.bin
    sha256: d1294032b937662efdc81462aa2fb972bf3f3725f690378891b477fbb5fce13f
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_1.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_1.bin
    sha256: 5098eb911b3e8b058373361683d72c14ed3c0ed159301636d2db354dd49ca634
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_1.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_K_M.bin
    sha256: f4ddbe96b8b59e606e2d06e0bf8fe88ca598515317089cfccb46c2800eae4884
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_K_S.bin
    sha256: 95f5d4365d00974fa29713047ee455824cd723300253f9e0ca202655bc8b8dd0
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_0.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_0.bin
    sha256: 44a8c79183ee24d08d31b6128615f36de3e727cfe5399c03e4a5516197da69bf
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_1.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_1.z01
    sha256: bc68165de81af13e021b04ef8e3b45ce8d245e05f3bdce17bfcddc65c1e2d794
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_1.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_1.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_1.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_1.zip
    sha256: 0d68754c1f1cf7979b35eaa6ec65c40efa39a1c672ee9b0ba734ab76aa4f06df
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_1.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_1.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_K_M.bin
    sha256: f4a8fb5da89841a07db3249a0173104682ded369b8820c1f42cb5d8d1f921e57
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_K_S.bin
    sha256: 4b17d429e565e0e7bc6c201e3a370d97365a0bd86a5de5aece487ba47e5469d2
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q6_K.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q6_K.z01
    sha256: 0c4f76da2d79e77d1a40ee6ee2dc344c5626727c13fc0b22755ccb25d6135dde
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q6_K.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q6_K.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q6_K.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q6_K.zip
    sha256: 901ea76caf455b679f8427643f57366d5d7b9a72f229240a312058546071db4e
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q6_K.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q6_K.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q8_0.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q8_0.z01
    sha256: 556dfbebbdcedc477dfb4e1701d254aa8308448a1ee49ad305852e6647442101
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q8_0.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q8_0.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q8_0.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q8_0.zip
    sha256: 58f3f36c20b94052c35341ec5aa6d51de0fe9a341723c8976a069a535253152b
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q8_0.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q8_0.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q2_K.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q2_K.bin
    sha256: d72768935527942c22cd48b36bc91600697c8384a458be6d6aa2d414e24826eb
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q2_K.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_L.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_L.bin
    sha256: 340f5b3f1968c93ed70c6c3be84011fc72bb19c15869abe13fb5879448cf88a4
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_L.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_M.bin
    sha256: 1ef4e22b579be5a0bd78191979f9d07516c42c9b8ec8467a99ee803d461d89a7
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_S.bin
    sha256: ae4f3741ef5d20cbcac8d844c8c0d4964d1128ff3dd85c7ff2f235f495e25827
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_0.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_0.bin
    sha256: d1294032b937662efdc81462aa2fb972bf3f3725f690378891b477fbb5fce13f
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_1.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_1.bin
    sha256: 5098eb911b3e8b058373361683d72c14ed3c0ed159301636d2db354dd49ca634
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_1.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_K_M.bin
    sha256: f4ddbe96b8b59e606e2d06e0bf8fe88ca598515317089cfccb46c2800eae4884
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_K_S.bin
    sha256: 95f5d4365d00974fa29713047ee455824cd723300253f9e0ca202655bc8b8dd0
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_0.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_0.bin
    sha256: 44a8c79183ee24d08d31b6128615f36de3e727cfe5399c03e4a5516197da69bf
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_1.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_1.z01
    sha256: bc68165de81af13e021b04ef8e3b45ce8d245e05f3bdce17bfcddc65c1e2d794
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_1.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_1.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_1.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_1.zip
    sha256: 0d68754c1f1cf7979b35eaa6ec65c40efa39a1c672ee9b0ba734ab76aa4f06df
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_1.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_1.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_K_M.bin
    sha256: f4a8fb5da89841a07db3249a0173104682ded369b8820c1f42cb5d8d1f921e57
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_K_S.bin
    sha256: 4b17d429e565e0e7bc6c201e3a370d97365a0bd86a5de5aece487ba47e5469d2
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q6_K.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q6_K.z01
    sha256: 0c4f76da2d79e77d1a40ee6ee2dc344c5626727c13fc0b22755ccb25d6135dde
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q6_K.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q6_K.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q6_K.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q6_K.zip
    sha256: 901ea76caf455b679f8427643f57366d5d7b9a72f229240a312058546071db4e
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q6_K.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q6_K.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q8_0.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q8_0.z01
    sha256: 556dfbebbdcedc477dfb4e1701d254aa8308448a1ee49ad305852e6647442101
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q8_0.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q8_0.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q8_0.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q8_0.zip
    sha256: 58f3f36c20b94052c35341ec5aa6d51de0fe9a341723c8976a069a535253152b
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q8_0.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q8_0.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q2_K.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q2_K.bin
    sha256: d72768935527942c22cd48b36bc91600697c8384a458be6d6aa2d414e24826eb
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q2_K.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_L.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_L.bin
    sha256: 340f5b3f1968c93ed70c6c3be84011fc72bb19c15869abe13fb5879448cf88a4
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_L.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_M.bin
    sha256: 1ef4e22b579be5a0bd78191979f9d07516c42c9b8ec8467a99ee803d461d89a7
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q3_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q3_K_S.bin
    sha256: ae4f3741ef5d20cbcac8d844c8c0d4964d1128ff3dd85c7ff2f235f495e25827
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q3_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_0.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_0.bin
    sha256: d1294032b937662efdc81462aa2fb972bf3f3725f690378891b477fbb5fce13f
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_1.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_1.bin
    sha256: 5098eb911b3e8b058373361683d72c14ed3c0ed159301636d2db354dd49ca634
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_1.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_K_M.bin
    sha256: f4ddbe96b8b59e606e2d06e0bf8fe88ca598515317089cfccb46c2800eae4884
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q4_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q4_K_S.bin
    sha256: 95f5d4365d00974fa29713047ee455824cd723300253f9e0ca202655bc8b8dd0
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q4_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_0.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_0.bin
    sha256: 44a8c79183ee24d08d31b6128615f36de3e727cfe5399c03e4a5516197da69bf
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_1.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_1.z01
    sha256: bc68165de81af13e021b04ef8e3b45ce8d245e05f3bdce17bfcddc65c1e2d794
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_1.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_1.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_1.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_1.zip
    sha256: 0d68754c1f1cf7979b35eaa6ec65c40efa39a1c672ee9b0ba734ab76aa4f06df
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_1.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_1.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_K_M.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_K_M.bin
    sha256: f4a8fb5da89841a07db3249a0173104682ded369b8820c1f42cb5d8d1f921e57
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q5_K_S.bin
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q5_K_S.bin
    sha256: 4b17d429e565e0e7bc6c201e3a370d97365a0bd86a5de5aece487ba47e5469d2
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q5_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q6_K.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q6_K.z01
    sha256: 0c4f76da2d79e77d1a40ee6ee2dc344c5626727c13fc0b22755ccb25d6135dde
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q6_K.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q6_K.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q6_K.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q6_K.zip
    sha256: 901ea76caf455b679f8427643f57366d5d7b9a72f229240a312058546071db4e
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q6_K.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q6_K.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q8_0.z01
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q8_0.z01
    sha256: 556dfbebbdcedc477dfb4e1701d254aa8308448a1ee49ad305852e6647442101
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q8_0.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q8_0.z01
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-70-x.ggmlv3.q8_0.zip
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/qCammel-70-x-GGML - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: qcammel-70-x.ggmlv3.q8_0.zip
    sha256: 58f3f36c20b94052c35341ec5aa6d51de0fe9a341723c8976a069a535253152b
    uri: 
      https://huggingface.co/TheBloke/qCammel-70-x-GGML/resolve/main/qcammel-70-x.ggmlv3.q8_0.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: thebloke__qcammel-70-x-ggml__qcammel-70-x.ggmlv3.q8_0.zip
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-70
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.70971
  - base_model:augtoma/qCammel-70-x
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-70-x-GGML
