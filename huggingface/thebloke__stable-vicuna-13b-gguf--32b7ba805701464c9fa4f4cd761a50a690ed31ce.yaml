- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q2_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q2_K.gguf
    sha256: c270bb6948d68aae48f9e53635d034e41c4c2d8a9be9c28b9358623978455cdf
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q3_K_L.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q3_K_L.gguf
    sha256: 62aa96e898183d4ca1497ecbe4f54d95f873abee24c0739ce409a6ef87b70282
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q3_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q3_K_M.gguf
    sha256: 5f0542a5f4db5a03c8bb75a7382b3e4c313fe9e99726660cee23cd7ac4ee89f1
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q3_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q3_K_S.gguf
    sha256: 64720eee6bb887f6192acac9aa902cbff3c6b433134ab20aad805a09bc9f61d5
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q4_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q4_0.gguf
    sha256: e583eb9c1063d90295ea214f3630731df93e0a294f694169dc260b1b64061654
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q4_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q4_K_M.gguf
    sha256: 4517130f30c24f43b52aefc5291d05309c6ba8bf1c14255cb0b11545913fa762
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q4_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q4_K_S.gguf
    sha256: 0dc625770e4628d33267bddc18ae97c0c820bf353cb7c0fa2d6b5f63c121bd2b
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q5_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q5_0.gguf
    sha256: b7a14bd46a7156dda220e91098ec9838c1bee80f149a823a30cac52d0238ca44
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q5_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q5_K_M.gguf
    sha256: 4bddc666b8d3ff810df30e27c485c48b6bc1ec08e7d49476cc1077d65021faac
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q5_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q5_K_S.gguf
    sha256: 6fc346537946169b96775b0a837d7cb695504bb2de8f2f6b6e0f3ff6df46a596
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q6_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q6_K.gguf
    sha256: 01689a054c1cd56d500ecb209ae08535c4f5626bb0fc4ee1daddb99f8a9aed4c
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q8_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llama configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q8_0.gguf
    sha256: d2c74adbc91ba939feda724ef4c6fd53f1287f65ffe31d98a38c9e7e6fb0d926
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q2_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q2_K.gguf
    sha256: c270bb6948d68aae48f9e53635d034e41c4c2d8a9be9c28b9358623978455cdf
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q2_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q3_K_L.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q3_K_L.gguf
    sha256: 62aa96e898183d4ca1497ecbe4f54d95f873abee24c0739ce409a6ef87b70282
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q3_K_L.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q3_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q3_K_M.gguf
    sha256: 5f0542a5f4db5a03c8bb75a7382b3e4c313fe9e99726660cee23cd7ac4ee89f1
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q3_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q3_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q3_K_S.gguf
    sha256: 64720eee6bb887f6192acac9aa902cbff3c6b433134ab20aad805a09bc9f61d5
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q3_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q4_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q4_0.gguf
    sha256: e583eb9c1063d90295ea214f3630731df93e0a294f694169dc260b1b64061654
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q4_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q4_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q4_K_M.gguf
    sha256: 4517130f30c24f43b52aefc5291d05309c6ba8bf1c14255cb0b11545913fa762
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q4_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q4_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q4_K_S.gguf
    sha256: 0dc625770e4628d33267bddc18ae97c0c820bf353cb7c0fa2d6b5f63c121bd2b
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q4_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q5_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q5_0.gguf
    sha256: b7a14bd46a7156dda220e91098ec9838c1bee80f149a823a30cac52d0238ca44
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q5_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q5_K_M.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q5_K_M.gguf
    sha256: 4bddc666b8d3ff810df30e27c485c48b6bc1ec08e7d49476cc1077d65021faac
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q5_K_M.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q5_K_S.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q5_K_S.gguf
    sha256: 6fc346537946169b96775b0a837d7cb695504bb2de8f2f6b6e0f3ff6df46a596
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q5_K_S.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q6_K.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q6_K.gguf
    sha256: 01689a054c1cd56d500ecb209ae08535c4f5626bb0fc4ee1daddb99f8a9aed4c
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q6_K.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: stable-vicuna-13B.Q8_0.gguf
    template:
      chat: vicuna
      completion: vicuna
  description: TheBloke/stable-vicuna-13B-GGUF - llamaFileFormatFallback configuration
  files:
  - filename: vicuna.tmpl
    sha256: 242a7459501a1d53298fdeb4e6cc71c34002a10d9dc4d6425f9fef8d70acb745
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/vicuna.tmpl
  - filename: stable-vicuna-13B.Q8_0.gguf
    sha256: d2c74adbc91ba939feda724ef4c6fd53f1287f65ffe31d98a38c9e7e6fb0d926
    uri: 
      https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF/resolve/main/stable-vicuna-13B.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: cc-by-nc-sa-4.0
  name: thebloke__stable-vicuna-13b-gguf__stable-vicuna-13B.Q8_0.gguf
  tags:
  - transformers
  - gguf
  - llama
  - causal-lm
  - en
  - dataset:OpenAssistant/oasst1
  - dataset:nomic-ai/gpt4all_prompt_generations
  - dataset:tatsu-lab/alpaca
  - arxiv:2302.13971
  - base_model:CarperAI/stable-vicuna-13b-delta
  - license:cc-by-nc-sa-4.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/stable-vicuna-13B-GGUF
